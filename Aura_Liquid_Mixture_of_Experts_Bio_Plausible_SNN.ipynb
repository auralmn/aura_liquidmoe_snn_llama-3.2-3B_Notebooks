{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNcHDUez+KYc1GTAQIWQ8sP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auralmn/aura_liquidmoe_snn_llama-3.2-3B_Notebooks/blob/main/Aura_Liquid_Mixture_of_Experts_Bio_Plausible_SNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The AURA Brain experiment #7\n",
        "### 2025-11-16\n",
        "### Author: Nicolas Cloutier\n",
        "### Entity: Cognitiv Aura\n",
        "### License: Apache 2.0\n",
        "*** note: not for production use, for experimentation only contact the owner for production use ***\n"
      ],
      "metadata": {
        "id": "wfARmII7gDoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- uninstall conflicting wandb ---\n",
        "!pip uninstall -y wandb\n",
        "\n",
        "# --- 1. Install All Dependencies ---\n",
        "!pip install \"unsloth[colab-new]\"\n",
        "!pip install transformers torch sentence-transformers accelerate huggingface_hub datasets scipy scikit-learn -q\n",
        "\n",
        "# --- 2. Import Core Libraries (for the whole notebook) ---\n",
        "import uuid\n",
        "import enum\n",
        "from enum import Enum # Explicitly import Enum as requested\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import itertools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, logging\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "from unsloth import FastLanguageModel\n",
        "from typing import List, Dict, Optional, Union, Any, Tuple, Literal\n",
        "from dataclasses import dataclass, field\n",
        "from abc import ABC, abstractmethod\n",
        "from numpy import ndarray\n",
        "import asyncio\n",
        "import io\n",
        "import csv\n",
        "import threading # For Memory Pool\n",
        "import time\n",
        "from scipy.signal import hilbert # For Temporal Interpolator\n",
        "from scipy.linalg import expm # For Temporal Interpolator\n",
        "import glob # For finding latest keyframe\n",
        "from datasets import load_dataset # For GoEmotions\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import nest_asyncio\n",
        "\n",
        "# Suppress transformer warnings\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# --- 3. Colab/HF Login ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN, add_to_git_credential=False)\n",
        "    print(\"Hugging Face login successful!\")\n",
        "except (ImportError, KeyError):\n",
        "    print(\"HF_TOKEN secret not found or not in Colab. Ensure you are logged in.\")\n",
        "\n",
        "# --- 4. Mount Google Drive ---\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    SAVE_DIR = \"/content/drive/MyDrive/aura_education_v7_final\" # New save dir\n",
        "    print(f\"Google Drive mounted. Will save/load brain from: {SAVE_DIR}\")\n",
        "except ImportError:\n",
        "    print(\"Not in Colab. Saving to local directory './aura_education_v7_final'\")\n",
        "    SAVE_DIR = \"./aura_education_v7_final\"\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "_f9MqN2TKQz6",
        "outputId": "f20715b4-b379-4629-ea8a-aaf40eb1aeff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting unsloth[colab-new]\n",
            "  Downloading unsloth-2025.11.3-py3-none-any.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth_zoo>=2025.11.4 (from unsloth[colab-new])\n",
            "  Downloading unsloth_zoo-2025.11.4-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.45.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (25.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.23.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (5.9.5)\n",
            "Collecting tyro (from unsloth[colab-new])\n",
            "  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (5.29.5)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth[colab-new])\n",
            "  Downloading xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth[colab-new])\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (3.4.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.2.1)\n",
            "Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth[colab-new])\n",
            "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (1.11.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.17.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.35.2)\n",
            "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.57.1)\n",
            "Collecting trl!=0.19.0,<=0.23.0,>=0.18.2 (from unsloth[colab-new])\n",
            "  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.20.0)\n",
            "Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new])\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.11.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth[colab-new]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth[colab-new]) (0.22.1)\n",
            "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.11.4->unsloth[colab-new])\n",
            "  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.11.4->unsloth[colab-new])\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.4->unsloth[colab-new]) (11.3.0)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.11.4->unsloth[colab-new])\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting torch>=2.4.0 (from unsloth[colab-new])\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.10.2.21->torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.1.2->torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.0.4->torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth[colab-new])\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth[colab-new])\n",
            "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth[colab-new]) (8.7.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from unsloth[colab-new])\n",
            "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth[colab-new])\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (4.4.4)\n",
            "\u001b[33mWARNING: unsloth 2025.11.3 does not provide the extra 'triton'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth[colab-new]) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth[colab-new]) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth[colab-new]) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.3.1)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.23.0-py3-none-any.whl (564 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.11.4-py3-none-any.whl (283 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m283.5/283.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m157.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m279.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core Helpers and SNN Components"
      ],
      "metadata": {
        "id": "KMT6XZxresnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import List, Dict, Optional, Union, Any, Tuple, Literal\n",
        "from dataclasses import dataclass, field\n",
        "from abc import ABC, abstractmethod\n",
        "from numpy import ndarray\n",
        "import threading\n",
        "from scipy.signal import hilbert\n",
        "from scipy.linalg import expm\n",
        "\n",
        "# --- 1. Helper Functions (Math) ---\n",
        "def softplus(z: np.ndarray) -> np.ndarray:\n",
        "    return np.log1p(np.exp(-np.abs(z))) + np.maximum(z, 0)\n",
        "def tanh(z: np.ndarray) -> np.ndarray:\n",
        "    return np.tanh(z)\n",
        "def softmax(z: np.ndarray, temp: float = 1.0) -> np.ndarray:\n",
        "    z = z / max(1e-8, temp); z = z - np.max(z); ez = np.exp(z)\n",
        "    s = ez.sum(); return ez / (s + 1e-12)\n",
        "\n",
        "# --- 2. EnergyMeter ---\n",
        "@dataclass\n",
        "class EnergyMeter:\n",
        "    e_mac_j: float = 3e-12; total_j: float = 0.0\n",
        "    def add_macs(self, nmacs: int): self.total_j += self.e_mac_j * float(nmacs)\n",
        "\n",
        "# --- 3. Memory Pool (from memory_pool.py) ---\n",
        "@dataclass\n",
        "class PoolStats:\n",
        "    hits: int = 0; misses: int = 0; total_allocations: int = 0; peak_usage_mb: float = 0.0\n",
        "class ArrayPool:\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, max_pool_size_mb: int = 512):\n",
        "        self.max_pool_size = max_pool_size_mb * 1024 * 1024\n",
        "        self.pools: Dict[Tuple[tuple, np.dtype], List[np.ndarray]] = {}\n",
        "        self.current_usage = 0; self.stats = PoolStats(); self._lock = threading.Lock()\n",
        "    def get_array(self, shape: tuple, dtype: np.dtype = np.float32, zero_fill: bool = True) -> np.ndarray:\n",
        "        key = (shape, dtype)\n",
        "        with self._lock:\n",
        "            if key in self.pools and self.pools[key]:\n",
        "                arr = self.pools[key].pop(); self.stats.hits += 1\n",
        "                if zero_fill: arr.fill(0); return arr\n",
        "            else:\n",
        "                arr = np.empty(shape, dtype=dtype);\n",
        "                if zero_fill: arr.fill(0)\n",
        "                self.stats.misses += 1; self.stats.total_allocations += 1; return arr\n",
        "    def return_array(self, arr: np.ndarray) -> None:\n",
        "        if arr is None: return\n",
        "        key = (arr.shape, arr.dtype); array_size = arr.nbytes\n",
        "        with self._lock:\n",
        "            if self.current_usage + array_size <= self.max_pool_size:\n",
        "                if key not in self.pools: self.pools[key] = []\n",
        "                arr.fill(0); self.pools[key].append(arr); self.current_usage += array_size\n",
        "_global_pool = ArrayPool()\n",
        "def get_pooled_array(shape: tuple, dtype: np.dtype = np.float32, zero_fill: bool = True) -> np.ndarray:\n",
        "    return _global_pool.get_array(shape, dtype, zero_fill)\n",
        "def return_pooled_array(arr: np.ndarray) -> None:\n",
        "    _global_pool.return_array(arr)\n",
        "\n",
        "# --- 4. Optimized Whitener ---\n",
        "class OptimizedWhitener:\n",
        "    def __init__(self, dim: int, eps: float = 1e-6, momentum: float = 0.01):\n",
        "        self.dim = dim; self.eps = np.float32(eps); self.momentum = np.float32(momentum)\n",
        "        self.mu = np.zeros(dim, dtype=np.float32); self.var = np.ones(dim, dtype=np.float32)\n",
        "    def transform(self, x: np.ndarray) -> np.ndarray:\n",
        "        if x.dtype != np.float32: x = x.astype(np.float32)\n",
        "        _temp_diff = get_pooled_array((self.dim,), dtype=np.float32)\n",
        "        _temp_result = get_pooled_array((self.dim,), dtype=np.float32)\n",
        "        self.mu *= (1.0 - self.momentum); self.mu += self.momentum * x\n",
        "        np.subtract(x, self.mu, out=_temp_diff)\n",
        "        np.multiply(_temp_diff, _temp_diff, out=_temp_result)\n",
        "        self.var *= (1.0 - self.momentum); self.var += self.momentum * _temp_result\n",
        "        np.sqrt(self.var + self.eps, out=_temp_result)\n",
        "        np.divide(_temp_diff, _temp_result, out=_temp_result)\n",
        "        result_copy = _temp_result.copy()\n",
        "        return_pooled_array(_temp_diff); return_pooled_array(_temp_result)\n",
        "        return result_copy\n",
        "    def state_dict(self) -> Dict: return {\"mu\": self.mu, \"var\": self.var}\n",
        "    def load_state_dict(self, state: Dict): self.mu = state[\"mu\"]; self.var = state[\"var\"]\n",
        "\n",
        "# --- 5. Hebbian Layer (Oja) ---\n",
        "@dataclass\n",
        "class OjaStepOut:\n",
        "    y: np.ndarray; residual_ema: float; grew: bool\n",
        "class OjaLayer:\n",
        "    def __init__(self, dim: int, n_components: int = 8, lr: float = 5e-4, mode: str = \"nonlinear\",\n",
        "                 *, max_components: int = 64, lateral_beta: float = 0.05,\n",
        "                 grow_threshold: float = 0.35, ema: float = 0.01, grow_cooldown: int = 100,\n",
        "                 seed: Optional[int] = 1337):\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.dim = int(dim); self.lr = float(lr); self.mode = str(mode)\n",
        "        self.max_components = int(max_components); self.beta = float(lateral_beta)\n",
        "        self.grow_threshold = float(grow_threshold); self.ema = float(ema)\n",
        "        self.grow_cooldown = int(grow_cooldown); self.cooldown = 0\n",
        "        W0 = self.rng.normal(0, 0.1, (n_components, self.dim))\n",
        "        self.W = (W0.T / (np.linalg.norm(W0, axis=1) + 1e-12)).T\n",
        "        self.K = self.W.shape[0]; self.residual_ema = 0.0; self._steps = 0\n",
        "        print(f\"CREATED: OjaLayer (Hebbian Cortex) with {self.K} components, mode='{self.mode}'\")\n",
        "    def step(self, xw: np.ndarray) -> OjaStepOut:\n",
        "        x = np.asarray(xw, dtype=np.float64); y = self.W @ x; x_hat = self.W.T @ y\n",
        "        xn = float(np.dot(x, x) + 1e-12); explained = float(np.dot(x_hat, x_hat) / xn)\n",
        "        residual = float(1.0 - explained)\n",
        "        if self.mode == \"nonlinear\":\n",
        "            g = y ** 3; dW = (g[:, None] * x[None, :]) - self.W\n",
        "        else:\n",
        "            proj = np.zeros_like(x); dW = np.zeros_like(self.W)\n",
        "            for i in range(self.K):\n",
        "                proj = proj + y[i] * self.W[i]; dW[i] = y[i] * (x - proj)\n",
        "        YW = y @ self.W; cross = YW[None, :] - (y[:, None] * self.W)\n",
        "        dW -= self.beta * (y[:, None] * cross); self.W += self.lr * dW; self._renorm_rows()\n",
        "        self.residual_ema = (1.0 - self.ema) * self.residual_ema + self.ema * residual\n",
        "        grew, _ = self._maybe_grow(x, x_hat); self._steps += 1\n",
        "        return OjaStepOut(y=y, residual_ema=self.residual_ema, grew=grew)\n",
        "    def _renorm_rows(self): self.W = (self.W.T / (np.linalg.norm(self.W, axis=1) + 1e-12)).T\n",
        "    def _maybe_grow(self, x: np.ndarray, x_hat: np.ndarray) -> Tuple[bool, Optional[int]]:\n",
        "        if self.cooldown > 0: self.cooldown -= 1; return False, None\n",
        "        if self.K >= self.max_components: return False, None\n",
        "        if self.residual_ema < self.grow_threshold: return False, None\n",
        "        r = x - x_hat; nr = float(np.linalg.norm(r))\n",
        "        if nr > 1e-9: w_new = r / nr\n",
        "        else:\n",
        "            w_new = self.rng.normal(0, 0.1, size=self.dim)\n",
        "            w_new /= (np.linalg.norm(w_new) + 1e-12)\n",
        "        self.W = np.vstack([self.W, w_new]); self.K += 1\n",
        "        self.cooldown = self.grow_cooldown\n",
        "        print(f\"ðŸ§¬ OJA NEUROGENESIS: Residual high. Growing new component. K={self.K}\"); return True, self.K - 1\n",
        "    def state_dict(self) -> Dict: return {\"W\": self.W, \"residual_ema\": self.residual_ema, \"_steps\": self._steps}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.W = state[\"W\"]; self.K = state[\"W\"].shape[0]; self.residual_ema = state[\"residual_ema\"]; self._steps = state[\"_steps\"]\n",
        "\n",
        "# --- 6. LiquidCell (from snn_nlms_moe.py) ---\n",
        "@dataclass\n",
        "class LiquidCell:\n",
        "    in_dim: int; hidden_dim: int; dt: float = 0.02\n",
        "    tau_min: float = 0.02; tau_max: float = 2.0\n",
        "    rng: np.random.Generator = field(default_factory=lambda: np.random.default_rng(1337))\n",
        "    W: np.ndarray = field(init=False); U: np.ndarray = field(init=False)\n",
        "    b: np.ndarray = field(init=False); V: np.ndarray = field(init=False)\n",
        "    c: np.ndarray = field(init=False); h: np.ndarray = field(init=False)\n",
        "    def __post_init__(self):\n",
        "        self.W = self.rng.normal(0, np.sqrt(2.0/(self.hidden_dim+self.hidden_dim)), (self.hidden_dim, self.hidden_dim))\n",
        "        self.U = self.rng.normal(0, np.sqrt(2.0/(self.in_dim+self.hidden_dim)), (self.hidden_dim, self.in_dim))\n",
        "        self.b = np.zeros((self.hidden_dim,), dtype=np.float64)\n",
        "        self.V = self.rng.normal(0, np.sqrt(2.0/(self.in_dim+self.hidden_dim)), (self.hidden_dim, self.in_dim))\n",
        "        self.c = self.rng.normal(0, 0.1, (self.hidden_dim,))\n",
        "        self.h = np.zeros((self.hidden_dim,), dtype=np.float64)\n",
        "    def reset(self): self.h[:] = 0.0\n",
        "    def step(self, x: np.ndarray, energy: Optional[EnergyMeter] = None) -> np.ndarray:\n",
        "        x = np.asarray(x, dtype=np.float64).reshape(-1)\n",
        "        vx = self.V @ x + self.c; tau = self.tau_min + softplus(vx)\n",
        "        tau = np.minimum(tau, self.tau_max)\n",
        "        Wh = self.W @ self.h; Ux = self.U @ x\n",
        "        a = tanh(Wh + Ux + self.b); dh = - self.h / np.maximum(tau, 1e-6) + a\n",
        "        self.h = self.h + self.dt * dh\n",
        "        if energy is not None: energy.add_macs((self.hidden_dim*self.hidden_dim) + (self.hidden_dim*self.in_dim))\n",
        "        return self.h.copy()\n",
        "    def state_dict(self) -> Dict: return {\"W\": self.W, \"U\": self.U, \"b\": self.b, \"V\": self.V, \"c\": self.c, \"h\": self.h}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.W = state[\"W\"]; self.U = state[\"U\"]; self.b = state[\"b\"]\n",
        "        self.V = state[\"V\"]; self.c = state[\"c\"]; self.h = state[\"h\"]\n",
        "\n",
        "# --- 7. TemporalInterpolator ---\n",
        "class TemporalMemoryInterpolator:\n",
        "    def __init__(self, epsilon: float = 1e-12):\n",
        "        self.epsilon = epsilon\n",
        "        print(\"CREATED: TemporalMemoryInterpolator (Aura 7.0 Hippocampus)\")\n",
        "    def interpolate(self, M0: np.ndarray, M1: np.ndarray, t: float,\n",
        "                    mode: Literal['linear', 'fourier', 'hilbert', 'hamiltonian'] = 'hilbert'\n",
        "                   ) -> np.ndarray:\n",
        "        alpha = np.clip(t, 0.0, 1.0)\n",
        "        if mode == 'linear': return (1.0 - alpha) * M0 + alpha * M1\n",
        "        elif mode == 'fourier':\n",
        "            F0 = np.fft.fft(M0); F1 = np.fft.fft(M1)\n",
        "            F_interp = (1.0 - alpha) * F0 + alpha * F1\n",
        "            return np.real(np.fft.ifft(F_interp))\n",
        "        A0 = hilbert(M0, axis=0); A1 = hilbert(M1, axis=0)\n",
        "        if mode == 'hilbert':\n",
        "            A_interp = (1.0 - alpha) * A0 + alpha * A1\n",
        "            return np.real(A_interp)\n",
        "        elif mode == 'hamiltonian':\n",
        "            print(\"WARNING: Hamiltonian mode is computationally expensive.\")\n",
        "            A_diff = (A1 - A0).astype(np.complex128)\n",
        "            H_num = np.outer(A_diff, A_diff.T.conj())\n",
        "            H_den = np.linalg.norm(A_diff)**2 + self.epsilon\n",
        "            H = H_num / H_den; U = expm(-1j * H * alpha)\n",
        "            A_interp = U @ A0; return np.real(A_interp)\n",
        "        else: raise ValueError(f\"Unknown interpolation mode: {mode}\")\n",
        "\n",
        "print(\"âœ… Cell 2: Core Brain Components & Helpers defined.\")"
      ],
      "metadata": {
        "id": "y6nouIDXe40V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ears and Mouth (I/O Components)"
      ],
      "metadata": {
        "id": "lQSiUH6Ye-bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import asyncio\n",
        "from transformers import AutoTokenizer, logging\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from unsloth import FastLanguageModel\n",
        "from typing import List, Dict, Optional, Union, Any\n",
        "from dataclasses import dataclass, field\n",
        "from abc import ABC, abstractmethod\n",
        "from numpy import ndarray\n",
        "import os\n",
        "\n",
        "# --- 3. GoEmotions Labels (The Curriculum) ---\n",
        "GOEMOTIONS_LABELS = [\n",
        "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
        "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
        "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
        "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
        "    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
        "]\n",
        "GOEMOTIONS_MAP = {label: idx for idx, label in enumerate(GOEMOTIONS_LABELS)}\n",
        "\n",
        "# --- 4. \"Ears\": FeatureGenerator (GoEmotions-Aware) ---\n",
        "class FeatureGenerator:\n",
        "    \"\"\"Based on clean_amygdala_trainer.py\"\"\"\n",
        "    def __init__(self, sbert_model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "        self.SBERT_DIM = 384; self.SINE_LENGTH = 32; self.EXTRA_FEATURES = 3\n",
        "        self.TOTAL_FEATURES = self.SBERT_DIM + self.SINE_LENGTH + self.EXTRA_FEATURES # 419\n",
        "        print(f\"CREATED: FeatureGenerator (Aura 7.0 Ears), Features: {self.TOTAL_FEATURES}\")\n",
        "        self.sbert_model = SentenceTransformer(sbert_model_name, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = self.sbert_model.tokenizer\n",
        "        self.vocab_size = self.tokenizer.vocab_size\n",
        "        self.label_params = self._generate_default_params(GOEMOTIONS_LABELS)\n",
        "        self.whitener = OptimizedWhitener(dim=self.TOTAL_FEATURES)\n",
        "\n",
        "    def _generate_default_params(self, labels: List[str]) -> Dict[str, Dict]:\n",
        "        params = {}\n",
        "        for idx, label in enumerate(labels):\n",
        "            params[label] = {\"freq\": 1.5 + 0.1 * idx, \"amp\": 0.7, \"phase\": 0.5 + 0.2 * idx}\n",
        "        return params\n",
        "\n",
        "    def build_features(self, record: Dict[str, Any], sbert_vec: np.ndarray) -> np.ndarray:\n",
        "        prim = record.get(\"plutchik\", {}).get(\"primary\", \"neutral\")\n",
        "        cfg = self.label_params.get(prim, {\"freq\": 1.0, \"amp\": 0.0, \"phase\": 0.0})\n",
        "        t = np.linspace(0, 2*np.pi, self.SINE_LENGTH, dtype=np.float32)\n",
        "        emb = (cfg[\"amp\"] * np.sin(cfg[\"freq\"] * t + cfg[\"phase\"])).astype(np.float32)\n",
        "        text = record.get(\"text\", \"\")\n",
        "        extras = np.array([len(text) / 100.0, int(\"!\" in text), int(\"?\" in text)], dtype=np.float32)\n",
        "        return np.concatenate([emb, extras, sbert_vec]).astype(np.float32)\n",
        "\n",
        "    def generate_for_query(self, query: str) -> (np.ndarray, List[int]):\n",
        "        record = {\"text\": query, \"plutchik\": {\"primary\": \"neutral\"}}\n",
        "        sbert_vec = self.sbert_model.encode(query, normalize_embeddings=True)\n",
        "        x_raw = self.build_features(record, sbert_vec)\n",
        "        x_whitened = self.whitener.transform(x_raw)\n",
        "        token_ids = self.tokenizer.encode(query, add_special_tokens=False)\n",
        "        return x_whitened, token_ids\n",
        "\n",
        "    def state_dict(self) -> Dict: return self.whitener.state_dict()\n",
        "    def load_state_dict(self, state: Dict): self.whitener.load_state_dict(state)\n",
        "\n",
        "# --- 5. \"Mouth\": ResponseGenerator (Unsloth, Async) ---\n",
        "class ResponseGenerator:\n",
        "    def __init__(self, model_name: str = \"meta-llama/Llama-3.2-3B-Instruct\"):\n",
        "        print(f\"CREATED: ResponseGenerator (Mouth) using Unsloth on '{model_name}'\")\n",
        "        max_seq_length = 2048; dtype = None; load_in_4bit = True\n",
        "        unsloth_model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
        "        print(f\"   -> Using optimized Unsloth 4-bit model: {unsloth_model_name}\")\n",
        "        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_name = unsloth_model_name, max_seq_length = max_seq_length,\n",
        "            dtype = dtype, load_in_4bit = load_in_4bit,\n",
        "        )\n",
        "        if self.tokenizer.pad_token is None: self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        print(\"   -> Unsloth Llama 3.2 model loaded successfully.\")\n",
        "    def _build_prompt(self, user_query: str, brain_state: dict) -> str:\n",
        "        cns_state = brain_state.get('cns_state', 'ALERT').name\n",
        "        stress = brain_state.get('stress_level', 0.0)\n",
        "        persona = f\"You are Aura, a bio-neural AI. Your current internal state is {cns_state}.\"\n",
        "        if cns_state == 'HYPERVIGILANT' or stress > 1.0:\n",
        "            persona += f\" You are feeling a high-stress level ({stress:.2f}).\"\n",
        "        else: persona += \" You are calm and helpful.\"\n",
        "        messages = [{\"role\": \"system\", \"content\": persona}, {\"role\": \"user\", \"content\": user_query}]\n",
        "        return self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    async def generate_response(self, user_query: str, brain_state: dict) -> str:\n",
        "        print(f\"\\n--- ðŸ‘„ ResponseGenerator (Unsloth) ---\"); print(f\"Generating response. Brain state: {brain_state}\")\n",
        "        prompt = self._build_prompt(user_query, brain_state)\n",
        "        inputs = self.tokenizer([prompt], return_tensors=\"pt\", padding=True, truncation=True, max_length=1024).to(\"cuda\")\n",
        "        terminators = [self.tokenizer.eos_token_id, self.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
        "        outputs = await asyncio.to_thread(\n",
        "            self.model.generate, **inputs, max_new_tokens=150, eos_token_id=terminators,\n",
        "            do_sample=True, temperature=0.7, top_p=0.9,\n",
        "        )\n",
        "        response_text = self.tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[-1]:], skip_special_tokens=True)[0]\n",
        "        print(f\"Llama 3.2 (Unsloth) Output: {response_text}\"); return response_text\n",
        "\n",
        "print(\"âœ… Cell 3: 'Ears' (FeatureGenerator) and 'Mouth' (ResponseGenerator) defined.\")"
      ],
      "metadata": {
        "id": "ijxQAEe9fC_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experts & Cortex (Learning & Routing)"
      ],
      "metadata": {
        "id": "Gtd1IM_WfHRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import asyncio\n",
        "from typing import List, Dict, Optional, Union, Any\n",
        "from dataclasses import dataclass, field\n",
        "from abc import ABC, abstractmethod\n",
        "from numpy import ndarray\n",
        "import os\n",
        "\n",
        "# --- 8. \"Expert Neuron\": ExpertNLMSHead ---\n",
        "class ExpertNLMSHead:\n",
        "    def __init__(self, n_features: int, vocab_size: int,\n",
        "                 attention_config: Dict, mu: float = 0.1, epsilon: float = 1e-6):\n",
        "        self.n_features = n_features\n",
        "        self.w = np.zeros(self.n_features, dtype=np.float64)\n",
        "        self.mu = mu; self.epsilon = epsilon; self.vocab_size = vocab_size\n",
        "        self.spiking_attention = SpikingAttention(**attention_config)\n",
        "        self.last_error = 0.0; self.last_output = 0.0\n",
        "        self._lock = asyncio.Lock()\n",
        "    def predict(self, x: np.ndarray) -> float:\n",
        "        return float(np.dot(self.w, x))\n",
        "    async def update(self, x: np.ndarray, y_true: float, token_ids: List[int]) -> float:\n",
        "        async with self._lock:\n",
        "            y_hat = self.predict(x); self.last_output = y_hat\n",
        "            error = y_true - y_hat; self.last_error = error\n",
        "            attention_gains = self.spiking_attention.compute_gains(token_ids, self.vocab_size)\n",
        "            avg_gain = 1.0\n",
        "            if attention_gains is not None and token_ids:\n",
        "                gains_for_seq = [attention_gains[token] for token in token_ids if 0 <= token < self.vocab_size]\n",
        "                if gains_for_seq: avg_gain = np.mean(gains_for_seq)\n",
        "            modulated_mu = self.mu * avg_gain\n",
        "            x_norm_sq = np.dot(x, x) + self.epsilon\n",
        "            step = (modulated_mu * error * x) / x_norm_sq\n",
        "            self.w += step; return y_hat\n",
        "    def state_dict(self) -> Dict: return {\"w\": self.w}\n",
        "    def load_state_dict(self, state: Dict): self.w = state[\"w\"]\n",
        "\n",
        "# --- 9. Liquid/MoE Components ---\n",
        "@dataclass\n",
        "class LiquidGatingNetwork:\n",
        "    in_dim: int; hidden_dim: int; n_experts: int\n",
        "    top_k: int = 2; temperature: float = 1.0\n",
        "    usage_smoothing: float = 0.99; bias_lr: float = 0.01\n",
        "    usage_beta: float = 0.5\n",
        "    cell: LiquidCell = field(init=False); Wg: np.ndarray = field(init=False)\n",
        "    bg: np.ndarray = field(init=False); usage_ma: np.ndarray = field(init=False)\n",
        "    rng: np.random.Generator = field(default_factory=lambda: np.random.default_rng(2025))\n",
        "    energy: EnergyMeter = field(default_factory=EnergyMeter)\n",
        "    def __post_init__(self):\n",
        "        self.cell = LiquidCell(self.in_dim, self.hidden_dim, rng=self.rng)\n",
        "        self.Wg = self.rng.normal(0, np.sqrt(2.0/(self.hidden_dim+self.n_experts)), (self.n_experts, self.hidden_dim))\n",
        "        self.bg = np.zeros((self.n_experts,), dtype=np.float64)\n",
        "        self.usage_ma = np.zeros((self.n_experts,), dtype=np.float64)\n",
        "        self._lock = asyncio.Lock()\n",
        "    async def forward(self, x: np.ndarray, attn_gain: float = 1.0) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        async with self._lock:\n",
        "            h = self.cell.step(x, self.energy)\n",
        "            logits = (self.Wg @ h) + self.bg\n",
        "            logits = self._apply_usage_bias(logits)\n",
        "            temp = max(0.2, self.temperature / max(1e-6, attn_gain))\n",
        "            probs = softmax(logits, temp=temp)\n",
        "            k = max(1, min(self.top_k, self.n_experts))\n",
        "            topk_idx = np.argpartition(probs, -k)[-k:]\n",
        "            topk_probs = probs[topk_idx]\n",
        "            if topk_probs.sum() <= 1e-12: gates = np.ones_like(topk_probs) / len(topk_probs)\n",
        "            else: gates = topk_probs / topk_probs.sum()\n",
        "            out = np.zeros_like(probs); out[topk_idx] = gates\n",
        "            eps = 0.01\n",
        "            if self.n_experts > 0 and eps > 0:\n",
        "                j = int(np.argmin(self.usage_ma)); out = (1.0 - eps) * out; out[j] += eps\n",
        "            self.usage_ma = self.usage_smoothing * self.usage_ma + (1.0 - self.usage_smoothing) * out\n",
        "            return out, topk_idx, probs\n",
        "    def _apply_usage_bias(self, logits: np.ndarray) -> np.ndarray:\n",
        "        eps = 1e-6; target = 1.0 / self.n_experts\n",
        "        inv_usage = target / (self.usage_ma + eps)\n",
        "        return logits + self.usage_beta * np.log(inv_usage)\n",
        "    async def apply_endocrine(self, *, cortisol: float = 0.0, **kwargs) -> None:\n",
        "        async with self._lock: self.temperature = float(np.clip(1.0 * (1.0 + 0.30 * cortisol), 0.5, 2.5))\n",
        "    async def nudge_for_load_balance(self) -> None:\n",
        "        async with self._lock:\n",
        "            if self.n_experts <= 0: return\n",
        "            target = 1.0 / float(self.n_experts); delta = target - self.usage_ma\n",
        "            self.bg += self.bias_lr * delta\n",
        "    def reset(self): self.cell.reset(); self.usage_ma[:] = 0.0; self.energy.reset()\n",
        "    def state_dict(self) -> Dict:\n",
        "        return {\"cell\": self.cell.state_dict(), \"Wg\": self.Wg, \"bg\": self.bg, \"usage_ma\": self.usage_ma}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.cell.load_state_dict(state[\"cell\"]); self.Wg = state[\"Wg\"]; self.bg = state[\"bg\"]; self.usage_ma = state[\"usage_ma\"]\n",
        "\n",
        "class NLMSExpertAdapter:\n",
        "    def __init__(self, neuron: ExpertNLMSHead): self.neuron = neuron\n",
        "    def predict(self, x: np.ndarray) -> float: return self.neuron.predict(x)\n",
        "    async def update(self, x: np.ndarray, y_true: float, token_ids: List[int]) -> float:\n",
        "        return await self.neuron.update(x, y_true, token_ids)\n",
        "    def state_dict(self) -> Dict: return self.neuron.state_dict()\n",
        "    def load_state_dict(self, state: Dict): self.neuron.load_state_dict(state)\n",
        "\n",
        "@dataclass\n",
        "class LiquidMoERouter:\n",
        "    experts: Dict[str, NLMSExpertAdapter]\n",
        "    in_dim: int; hidden_dim: int; top_k: int = 2\n",
        "    temperature: float = 1.0\n",
        "    gating: LiquidGatingNetwork = field(init=False)\n",
        "    names: List[str] = field(init=False)\n",
        "    energy: EnergyMeter = field(default_factory=EnergyMeter)\n",
        "    def __post_init__(self):\n",
        "        self.names = list(self.experts.keys())\n",
        "        self.gating = LiquidGatingNetwork(\n",
        "            in_dim=self.in_dim, hidden_dim=self.hidden_dim,\n",
        "            n_experts=len(self.names), top_k=self.top_k,\n",
        "            temperature=self.temperature,\n",
        "        )\n",
        "    async def route(self, x: np.ndarray, attn_gain: float = 1.0) -> Dict[str, any]:\n",
        "        gates_sparse, topk_idx, probs = await self.gating.forward(x, attn_gain=attn_gain)\n",
        "        chosen = [(self.names[i], float(gates_sparse[i])) for i in topk_idx]\n",
        "        y = 0.0; per_expert: Dict[str, Dict[str, float]] = {}\n",
        "        for i in topk_idx:\n",
        "            name = self.names[int(i)]; gate = float(gates_sparse[i])\n",
        "            pred = float(self.experts[name].predict(x)); y += gate * pred\n",
        "            self.energy.add_macs(self.in_dim); per_expert[name] = {\"gate\": gate, \"pred\": pred}\n",
        "        return {'y_hat': float(y), 'topk': chosen, 'probs': probs, 'per_expert': per_expert,\n",
        "            'energy_j': self.energy.total_j + self.gating.energy.total_j}\n",
        "    async def learn(self, x: np.ndarray, token_ids: List[int], y_true: float, attn_gain: float = 1.0) -> Dict[str, any]:\n",
        "        out = await self.route(x, attn_gain=attn_gain); tasks = []\n",
        "        for name, info in out['per_expert'].items():\n",
        "            gate = float(info['gate']);\n",
        "            if gate <= 0.0: continue\n",
        "            target = float(y_true)\n",
        "            tasks.append(self.experts[name].update(x, target, token_ids))\n",
        "        await asyncio.gather(*tasks); await self.gating.nudge_for_load_balance(); return out\n",
        "    def reset(self): self.gating.reset(); self.energy.reset()\n",
        "    def state_dict(self) -> Dict:\n",
        "        expert_states = {name: expert.state_dict() for name, expert in self.experts.items()}\n",
        "        return {\"gating\": self.gating.state_dict(), \"experts\": expert_states}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.gating.load_state_dict(state[\"gating\"])\n",
        "        for name, expert_state in state[\"experts\"].items():\n",
        "            if name in self.experts: self.experts[name].load_state_dict(expert_state)\n",
        "\n",
        "print(\"âœ… Cell 4: 'Expert' (NLMSHead) and 'Cortex' (LiquidMoERouter) defined.\")"
      ],
      "metadata": {
        "id": "X1lAiiJIfSPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# School, Central Nervous System (CNS) & Thalamus (Control)"
      ],
      "metadata": {
        "id": "V2fdbXcFfX_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import asyncio\n",
        "from typing import List, Dict, Optional, Union, Any\n",
        "from dataclasses import dataclass, field\n",
        "from abc import ABC, abstractmethod\n",
        "from numpy import ndarray\n",
        "import os\n",
        "from enum import Enum # <-- User requested import\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# --- 11. CNS & ThalamicRouter (Trained) ---\n",
        "class ConsciousnessLevel(Enum):\n",
        "    DEEP_SLEEP = 0; ASLEEP = 1; ALERT = 2; FOCUSED = 3; HYPERVIGILANT = 4\n",
        "class CentralNervousSystem:\n",
        "    def __init__(self):\n",
        "        self.consciousness_level = ConsciousnessLevel.ALERT\n",
        "        self.stress_level = 0.0 # 'cortisol'\n",
        "        print(\"CREATED: CentralNervousSystem (CNS)\")\n",
        "    def set_consciousness(self, level: ConsciousnessLevel):\n",
        "        if self.consciousness_level != level:\n",
        "            self.consciousness_level = level; print(f\"CNS: Consciousness set to {level.name}\")\n",
        "    def update_stress(self, error: float):\n",
        "        new_stress = abs(error) * 1.5\n",
        "        self.stress_level = (self.stress_level * 0.5) + (new_stress * 0.5)\n",
        "        self.stress_level = max(0.0, self.stress_level - 0.1)\n",
        "        if self.stress_level > 1.0: self.set_consciousness(ConsciousnessLevel.HYPERVIGILANT)\n",
        "        else: self.set_consciousness(ConsciousnessLevel.ALERT)\n",
        "\n",
        "class TrainedThalamicRouter:\n",
        "    \"\"\"The 'School' - runs the offline-trained PyTorch model\"\"\"\n",
        "    def __init__(self, model_path: str, label_maps: Dict, feature_gen: FeatureGenerator):\n",
        "        self.label_maps = label_maps\n",
        "        self.emotion_map = label_maps.get('emotion', {})\n",
        "        self.intent_map = label_maps.get('intent', {})\n",
        "        self.emotion_labels_inv = {v: k for k, v in self.emotion_map.items()}\n",
        "        self.feature_gen = feature_gen; self.model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        try:\n",
        "            self.model = MultiTaskHead(\n",
        "                feature_gen.TOTAL_FEATURES,\n",
        "                len(self.emotion_map), len(self.intent_map), len(self.emotion_map) # Mock tone\n",
        "            ).to(self.device)\n",
        "            self.model.load_state_dict(torch.load(model_path))\n",
        "            self.model.eval()\n",
        "            print(f\"CREATED: TrainedThalamicRouter (Loaded from {model_path})\")\n",
        "        except Exception as e:\n",
        "            print(f\"--- âŒ ERROR: Failed to load ThalamicRouter model. {e} ---\")\n",
        "\n",
        "    def get_target_signals(self, query: str) -> dict:\n",
        "        if not self.model: return {'emotion': 0.0, 'intent': 0.0}\n",
        "        record = {\"text\": query, \"plutchik\": {\"primary\": \"neutral\"}}\n",
        "        sbert_vec = self.feature_gen.sbert_model.encode(query, normalize_embeddings=True)\n",
        "        x_raw = self.feature_gen.build_features(record, sbert_vec)\n",
        "        x_tensor = torch.tensor(x_raw, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            emo_logits, intent_logits, _ = self.model(x_tensor)\n",
        "            emo_pred_index = emo_logits.argmax(dim=1).item()\n",
        "            intent_pred_index = intent_logits.argmax(dim=1).item()\n",
        "        pred_label = self.emotion_labels_inv.get(emo_pred_index, 'neutral')\n",
        "        signals = {'emotion': float(emo_pred_index), 'intent': float(intent_pred_index)}\n",
        "        print(f\"Thalamus Predicted: '{pred_label}' (Index: {emo_pred_index})\")\n",
        "        return signals\n",
        "\n",
        "# --- 12. PyTorch Models (for the \"School\") ---\n",
        "class LinearTorchModel(nn.Module):\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, input_dim: int, num_classes: int):\n",
        "        super().__init__(); self.fc = nn.Linear(input_dim, num_classes)\n",
        "    def forward(self, x): return self.fc(x)\n",
        "\n",
        "class MultiTaskHead(nn.Module):\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, input_dim: int, num_emotions: int, num_intents: int, num_tones: int):\n",
        "        super().__init__(); self.shared = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Dropout(0.1))\n",
        "        self.emotion_head = nn.Linear(256, num_emotions)\n",
        "        self.intent_head = nn.Linear(256, num_intents)\n",
        "        self.tone_head = nn.Linear(256, num_tones)\n",
        "    def forward(self, x):\n",
        "        h = self.shared(x); return self.emotion_head(h), self.intent_head(h), self.tone_head(h)\n",
        "\n",
        "def multitask_loss(emotion_out, emotion_y, intent_out, intent_y, tone_out, tone_y,\n",
        "                  weights=(1.0, 0.7, 0.7)):\n",
        "    \"\"\"\"\"\"\n",
        "    ce = nn.CrossEntropyLoss(); return (weights[0] * ce(emotion_out, emotion_y) +\n",
        "            weights[1] * ce(intent_out, intent_y) + weights[2] * ce(tone_out, tone_y))\n",
        "\n",
        "print(\"âœ… Cell 5: 'CNS', 'Thalamus', and 'School' (PyTorch) models defined.\")"
      ],
      "metadata": {
        "id": "bFe_JPczfgFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The IntegratedBioNeuralNetwork v 7.0"
      ],
      "metadata": {
        "id": "zb8PZXnyfi87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import asyncio\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "from typing import List, Dict, Optional, Union, Any\n",
        "from dataclasses import dataclass, field\n",
        "from abc import ABC, abstractmethod\n",
        "from numpy import ndarray\n",
        "from datasets import load_dataset\n",
        "\n",
        "# --- 14. The Final IBNN (Aura 7.0 - Hebbian-MoE-Temporal) ---\n",
        "class IntegratedBioNeuralNetwork:\n",
        "    \"\"\"\n",
        "    Aura 7.0: Integrates all components into a persistent,\n",
        "    unsupervised-learning, and time-aware architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_experts: int = 10, hebbian_components: int = 64,\n",
        "                 llm_model_name: str = \"meta-llama/Llama-3.2-3B-Instruct\"):\n",
        "        print(\"--- ðŸ§  Initializing Aura 7.0 (Hebbian-MoE-Temporal) ---\")\n",
        "        self.feature_gen = FeatureGenerator()\n",
        "        self.response_gen = ResponseGenerator(llm_model_name)\n",
        "        self.cns = CentralNervousSystem()\n",
        "        self.interpolator = TemporalMemoryInterpolator()\n",
        "        self.raw_feature_dim = self.feature_gen.TOTAL_FEATURES\n",
        "        self.vocab_size = self.feature_gen.vocab_size\n",
        "        self.abstract_feature_dim = hebbian_components\n",
        "\n",
        "        self.whitener: OptimizedWhitener = None\n",
        "        self.hippocampus: OjaLayer = None # Hebbian Cortex\n",
        "        self.cortex: LiquidMoERouter = None # MoE Cortex\n",
        "        self.router: Optional[TrainedThalamicRouter] = None\n",
        "        self.n_experts = n_experts\n",
        "\n",
        "        self.education_dir = SAVE_DIR # Use the global SAVE_DIR\n",
        "        os.makedirs(self.education_dir, exist_ok=True)\n",
        "        print(\"--- Aura 7.0 Brain Initialized (Awaiting Education) ---\")\n",
        "\n",
        "    def _create_brain_layers(self, hebbian_k: int):\n",
        "        \"\"\"Dynamically creates the brain layers based on the Hebbian cortex size.\"\"\"\n",
        "        self.abstract_feature_dim = hebbian_k\n",
        "        print(f\"--- ðŸ§  Building Dynamic Brain Layers ---\")\n",
        "        print(f\"   -> Hebbian Cortex (Oja) K = {hebbian_k}\")\n",
        "\n",
        "        self.hippocampus = OjaLayer(\n",
        "            dim=self.raw_feature_dim,\n",
        "            n_components=hebbian_k,\n",
        "            mode='nonlinear', lr=5e-4, max_components=128, grow_threshold=0.3\n",
        "        )\n",
        "        self.whitener = OptimizedWhitener(dim=self.raw_feature_dim)\n",
        "\n",
        "        experts: Dict[str, NLMSExpertAdapter] = {}\n",
        "        attention_config = {'decay': 0.7, 'k_winners': 3, 'gain_up': 1.5, 'gain_down': 0.7}\n",
        "        for i in range(self.n_experts):\n",
        "            name = f\"expert__{i}\"\n",
        "            head = ExpertNLMSHead(\n",
        "                n_features=self.abstract_feature_dim, # Use K\n",
        "                vocab_size=self.vocab_size,\n",
        "                attention_config=attention_config, mu=0.1\n",
        "            )\n",
        "            experts[name] = NLMSExpertAdapter(neuron=head)\n",
        "\n",
        "        self.cortex = LiquidMoERouter(\n",
        "            experts=experts, in_dim=self.abstract_feature_dim, # Use K\n",
        "            hidden_dim=128, top_k=3\n",
        "        )\n",
        "        print(f\"--- ðŸ§  Dynamic Brain Layers Created ---\")\n",
        "\n",
        "    async def educate_brain(self):\n",
        "        \"\"\"\n",
        "        Runs the 'School' pipeline to pre-train all components.\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"\\n--- ðŸŽ“ STARTING OFFLINE EDUCATION (GoEmotions) ---\")\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        # 1. Load GoEmotions\n",
        "        print(\"Loading 'google-research-datasets/go_emotions'...\")\n",
        "        dataset = load_dataset(\"google-research-datasets/go_emotions\", split='train')\n",
        "        dataset = dataset.shuffle(seed=42).select(range(15000)) # Use 15000 samples\n",
        "        all_texts = dataset['text']\n",
        "\n",
        "        # 2. Precompute SBERT\n",
        "        print(f\"Pre-computing SBERT embeddings for {len(all_texts)} texts...\")\n",
        "        sbert_embeddings = await asyncio.to_thread(\n",
        "            self.feature_gen.sbert_model.encode,\n",
        "            all_texts, normalize_embeddings=True, batch_size=64\n",
        "        )\n",
        "\n",
        "        # 3. Create Label Maps\n",
        "        emotion_labels = GOEMOTIONS_LABELS\n",
        "        intent_labels = [\"question\", \"statement\", \"exclamation\", \"request\", \"none\"]\n",
        "        tone_labels = emotion_labels # Mock\n",
        "        label_maps = {\n",
        "            'emotion': {label: idx for idx, label in enumerate(emotion_labels)},\n",
        "            'intent': {label: idx for idx, label in enumerate(intent_labels)},\n",
        "            'tone': {label: idx for idx, label in enumerate(tone_labels)},\n",
        "        }\n",
        "\n",
        "        # 4. Build Features\n",
        "        print(\"Building features...\")\n",
        "        X_features, y_emotion, y_intent, y_tone = [], [], [], []\n",
        "        for i, record in enumerate(dataset):\n",
        "            primary_emotion = 'neutral'\n",
        "            label_indices = record['labels']\n",
        "            if label_indices:\n",
        "                for idx in label_indices:\n",
        "                    if 0 <= idx < len(GOEMOTIONS_LABELS):\n",
        "                        label_name = GOEMOTIONS_LABELS[idx]\n",
        "                        if label_name != 'neutral':\n",
        "                            primary_emotion = label_name; break\n",
        "\n",
        "            mock_record = {\n",
        "                \"text\": record['text'],\n",
        "                \"plutchik\": {\"primary\": primary_emotion, \"intensity\": 1.0},\n",
        "                \"intent\": \"question\" if \"?\" in record['text'] else \"statement\",\n",
        "                \"tone\": primary_emotion\n",
        "            }\n",
        "            X_features.append(self.feature_gen.build_features(mock_record, sbert_embeddings[i]))\n",
        "            y_emotion.append(label_maps['emotion'].get(primary_emotion, GOEMOTIONS_MAP['neutral']))\n",
        "            y_intent.append(label_maps['intent'].get(mock_record['intent'], 1))\n",
        "            y_tone.append(label_maps['tone'].get(primary_emotion, GOEMOTIONS_MAP['neutral']))\n",
        "\n",
        "        X_train_np = np.stack(X_features)\n",
        "        y_emotion_np = np.array(y_emotion)\n",
        "\n",
        "        indices = np.arange(len(X_train_np))\n",
        "        X_train_split, X_test_split, y_emotion_train_split, y_emotion_test_split, \\\n",
        "        y_intent_train_split, y_intent_test_split, y_tone_train_split, y_tone_test_split = \\\n",
        "            train_test_split(X_train_np, y_emotion_np, y_intent, y_tone, test_size=0.2, random_state=42, stratify=y_emotion_np)\n",
        "\n",
        "        X_train_torch = torch.tensor(X_train_split, dtype=torch.float32).to(device)\n",
        "        y_emotion_train_torch = torch.tensor(y_emotion_train_split, dtype=torch.long).to(device)\n",
        "        y_intent_train_torch = torch.tensor(y_intent_train_split, dtype=torch.long).to(device)\n",
        "        y_tone_train_torch = torch.tensor(y_tone_train_split, dtype=torch.long).to(device)\n",
        "\n",
        "        X_test_torch = torch.tensor(X_test_split, dtype=torch.float32).to(device)\n",
        "        y_emotion_test_torch = torch.tensor(y_emotion_test_split, dtype=torch.long).to(device)\n",
        "\n",
        "        # --- 5. Train the \"Hebbian Cortex\" (OjaLayer) ---\n",
        "        print(\"Training Hebbian Cortex (OjaLayer) on whitened data...\")\n",
        "        self._create_brain_layers(hebbian_k=self.abstract_feature_dim)\n",
        "\n",
        "        X_features_whitened = np.array([self.feature_gen.whitener.transform(x) for x in X_train_np])\n",
        "        for x_w in X_features_whitened:\n",
        "             self.hippocampus.step(x_w)\n",
        "\n",
        "        final_k = self.hippocampus.K\n",
        "        if final_k != self.abstract_feature_dim:\n",
        "            print(f\"Hebbian Cortex grew from {self.abstract_feature_dim} to {final_k}. Rebuilding MoE...\")\n",
        "            self._create_brain_layers(hebbian_k=final_k)\n",
        "\n",
        "        print(f\"   -> Hebbian Cortex (OjaLayer) training complete. Final K={final_k}\")\n",
        "\n",
        "        # --- 6. Train the \"Thalamus\" (MultiTaskHead) ---\n",
        "        print(f\"Training MultiTask ThalamicRouter...\")\n",
        "        class_weights_emotion = compute_class_weight('balanced', classes=np.unique(y_emotion_train_split), y=y_emotion_train_split)\n",
        "        class_weights_emotion = torch.tensor(class_weights_emotion, dtype=torch.float32).to(device)\n",
        "\n",
        "        thalamus_model = MultiTaskHead(\n",
        "            self.feature_gen.TOTAL_FEATURES,\n",
        "            len(label_maps['emotion']), len(label_maps['intent']), len(label_maps['tone'])\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = optim.AdamW(thalamus_model.parameters(), lr=5e-3)\n",
        "        criterion_emotion = nn.CrossEntropyLoss(weight=class_weights_emotion)\n",
        "        criterion_intent = nn.CrossEntropyLoss()\n",
        "        criterion_tone = nn.CrossEntropyLoss(weight=class_weights_emotion)\n",
        "\n",
        "        for epoch in range(30): # More epochs\n",
        "            thalamus_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            emo_out, intent_out, tone_out = thalamus_model(X_train_torch)\n",
        "            loss = (1.0 * criterion_emotion(emo_out, y_emotion_train_torch) +\n",
        "                    0.5 * criterion_intent(intent_out, y_intent_train_torch) +\n",
        "                    0.5 * criterion_tone(tone_out, y_tone_train_torch))\n",
        "            loss.backward(); optimizer.step()\n",
        "\n",
        "        thalamus_model.eval()\n",
        "        with torch.no_grad():\n",
        "            emo_preds_test, _, _ = thalamus_model(X_test_torch)\n",
        "            emo_preds_test = emo_preds_test.argmax(dim=1)\n",
        "            test_acc = accuracy_score(y_emotion_test_torch.cpu(), emo_preds_test.cpu())\n",
        "            print(f\"   -> Thalamus (Emotion) Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "        thalamus_path = os.path.join(self.education_dir, \"thalamic_router_multitask.pt\")\n",
        "        torch.save(thalamus_model.state_dict(), thalamus_path)\n",
        "        print(f\"   -> ThalamicRouter trained and saved to {thalamus_path}\")\n",
        "\n",
        "        # --- 7. \"Mind Upload\" - Initialize Router ---\n",
        "        self.router = TrainedThalamicRouter(thalamus_path, label_maps, self.feature_gen)\n",
        "        print(\"--- ðŸŽ“ OFFLINE EDUCATION COMPLETE ---\")\n",
        "\n",
        "    async def process_query(self, query: str) -> str:\n",
        "        print(f\"\\n--- â˜€ï¸ PROCESSING QUERY (Aura 7.0): '{query}' ---\")\n",
        "        if not self.router: return \"I am uneducated. Please run `await aura.educate_brain()`.\"\n",
        "\n",
        "        cns_level = self.cns.consciousness_level\n",
        "        x_raw, token_ids = self.feature_gen.generate_for_query(query)\n",
        "        xw = self.feature_gen.whitener.transform(x_raw)\n",
        "        oja_out = self.hippocampus.step(xw)\n",
        "        y_abstract = oja_out.y\n",
        "\n",
        "        target_signals = self.router.get_target_signals(query)\n",
        "        y_true_emotion_idx = target_signals['emotion']\n",
        "        target_for_moe = float(y_true_emotion_idx)\n",
        "\n",
        "        out = await self.cortex.learn(\n",
        "            x=y_abstract, token_ids=token_ids, y_true=target_for_moe\n",
        "        )\n",
        "\n",
        "        last_prediction = out['y_hat']\n",
        "        prediction_error = target_for_moe - last_prediction\n",
        "        self.cns.update_stress(prediction_error)\n",
        "\n",
        "        print(f\"Hebbian (Oja) Residual: {oja_out.residual_ema:.3f} (Grew: {oja_out.grew})\")\n",
        "        print(f\"MoE Prediction: {last_prediction:.2f}, Error (Stress): {abs(prediction_error):.2f}\")\n",
        "\n",
        "        final_brain_state = {\n",
        "            'cns_state': self.cns.consciousness_level,\n",
        "            'stress_level': self.cns.stress_level,\n",
        "        }\n",
        "        response = await self.response_gen.generate_response(query, final_brain_state)\n",
        "        self.last_run_final_stress = self.cns.stress_level\n",
        "        return response\n",
        "\n",
        "    def _get_brain_state_vector(self) -> np.ndarray:\n",
        "        all_weights = []\n",
        "        all_weights.append(self.feature_gen.whitener.mu.flatten())\n",
        "        all_weights.append(self.feature_gen.whitener.var.flatten())\n",
        "        all_weights.append(self.hippocampus.W.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.W.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.U.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.b.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.V.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.c.flatten())\n",
        "        all_weights.append(self.cortex.gating.Wg.flatten())\n",
        "        all_weights.append(self.cortex.gating.bg.flatten())\n",
        "        for expert in self.cortex.experts.values():\n",
        "            all_weights.append(expert.neuron.w.flatten())\n",
        "        return np.concatenate(all_weights)\n",
        "\n",
        "    def _load_brain_state_vector(self, M: np.ndarray):\n",
        "        print(\"--- ðŸ§  Loading brain state from vector... ---\")\n",
        "        idx = 0\n",
        "        def _load(target_array: np.ndarray) -> int:\n",
        "            nonlocal idx\n",
        "            n = target_array.size\n",
        "            try:\n",
        "                target_array[:] = M[idx : idx + n].reshape(target_array.shape)\n",
        "            except ValueError:\n",
        "                print(f\"!! Shape mismatch during load. Target: {target_array.shape}, Got: {M[idx : idx + n].shape}\")\n",
        "                min_n = min(target_array.size, M[idx:].size)\n",
        "                if min_n == 0: return idx\n",
        "                target_flat = target_array.flat; source_flat = M[idx:].flat\n",
        "                for i in range(min_n): target_flat[i] = source_flat[i]\n",
        "                n = min_n\n",
        "            return idx + n\n",
        "        try:\n",
        "            idx = _load(self.feature_gen.whitener.mu)\n",
        "            idx = _load(self.feature_gen.whitener.var)\n",
        "            idx = _load(self.hippocampus.W)\n",
        "            idx = _load(self.cortex.gating.cell.W)\n",
        "            idx = _load(self.cortex.gating.cell.U)\n",
        "            idx = _load(self.cortex.gating.cell.b)\n",
        "            idx = _load(self.cortex.gating.cell.V)\n",
        "            idx = _load(self.cortex.gating.cell.c)\n",
        "            idx = _load(self.cortex.gating.Wg)\n",
        "            idx = _load(self.cortex.gating.bg)\n",
        "            for expert in self.cortex.experts.values():\n",
        "                idx = _load(expert.neuron.w)\n",
        "            print(f\"--- ðŸ§  Brain state loaded successfully. Total params: {idx} ---\")\n",
        "        except Exception as e:\n",
        "            print(f\"--- âŒ ERROR: Failed to load brain state vector. {e} ---\")\n",
        "\n",
        "    async def save_keyframe(self, name: str):\n",
        "        path = os.path.join(self.education_dir, f\"keyframe_{name}_{int(time.time())}.npy\")\n",
        "        print(f\"\\n--- ðŸ’¾ Saving keyframe to {path} ---\")\n",
        "        M = self._get_brain_state_vector()\n",
        "        await asyncio.to_thread(np.save, path, M)\n",
        "        print(\"--- ðŸ’¾ Keyframe save complete ---\")\n",
        "\n",
        "    async def run_sleep_cycle(self, keyframe1_name: str, keyframe2_name: str):\n",
        "        \"\"\"\"\"\"\n",
        "        print(f\"\\n--- ðŸ’¤ RUNNING SLEEP CYCLE (Dreaming) ---\")\n",
        "        print(f\"Loading keyframes: {keyframe1_name} and {keyframe2_name}\")\n",
        "        try:\n",
        "            M0_path = sorted(glob.glob(os.path.join(self.education_dir, f\"keyframe_{keyframe1_name}*.npy\")))[-1]\n",
        "            M1_path = sorted(glob.glob(os.path.join(self.education_dir, f\"keyframe_{keyframe2_name}*.npy\")))[-1]\n",
        "            M0 = np.load(M0_path)\n",
        "            M1 = np.load(M1_path)\n",
        "        except Exception as e:\n",
        "            print(f\"--- âŒ ERROR: Could not load keyframes for dreaming. {e} ---\"); return\n",
        "\n",
        "        current_brain_shape = self._get_brain_state_vector().shape\n",
        "        if M0.shape != M1.shape or M0.shape != current_brain_shape:\n",
        "            print(f\"--- âŒ ERROR: Keyframe dimension mismatch. Cannot interpolate. ---\")\n",
        "            print(f\"M0: {M0.shape}, M1: {M1.shape}, Current: {current_brain_shape}\"); return\n",
        "\n",
        "        print(\"...Interpolating dream state using Hilbert (phase-aware) interpolation...\")\n",
        "        M_dream = self.interpolator.interpolate(M0, M1, t=0.5, mode='hilbert')\n",
        "        self._load_brain_state_vector(M_dream)\n",
        "\n",
        "        print(\"...Consolidating dream state...\")\n",
        "        await self.process_query(\"... (dreaming) ...\")\n",
        "        print(\"--- ðŸ’¤ SLEEP CYCLE COMPLETE ---\")\n",
        "\n",
        "# --- 15. PyTorch Models (for the \"School\") ---\n",
        "class LinearTorchModel(nn.Module):\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, input_dim: int, num_classes: int):\n",
        "        super().__init__(); self.fc = nn.Linear(input_dim, num_classes)\n",
        "    def forward(self, x): return self.fc(x)\n",
        "\n",
        "class MultiTaskHead(nn.Module):\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, input_dim: int, num_emotions: int, num_intents: int, num_tones: int):\n",
        "        super().__init__(); self.shared = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Dropout(0.1))\n",
        "        self.emotion_head = nn.Linear(256, num_emotions)\n",
        "        self.intent_head = nn.Linear(256, num_intents)\n",
        "        self.tone_head = nn.Linear(256, num_tones)\n",
        "    def forward(self, x):\n",
        "        h = self.shared(x); return self.emotion_head(h), self.intent_head(h), self.tone_head(h)\n",
        "\n",
        "def multitask_loss(emotion_out, emotion_y, intent_out, intent_y, tone_out, tone_y,\n",
        "                  weights=(1.0, 0.7, 0.7)):\n",
        "    \"\"\"\"\"\"\n",
        "    ce = nn.CrossEntropyLoss(); return (weights[0] * ce(emotion_out, emotion_y) +\n",
        "            weights[1] * ce(intent_out, intent_y) + weights[2] * ce(tone_out, tone_y))\n",
        "\n",
        "print(\"âœ… Cell 6: `IntegratedBioNeuralNetwork` (Aura 7.0) defined.\")"
      ],
      "metadata": {
        "id": "FBz9i8T8fpka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST v7.0 (AURA v1)\n"
      ],
      "metadata": {
        "id": "zkOtqj4ufwtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- This is the test cell for Aura 7.0 ---\n",
        "# It must be run in a cell *after* Cell 6\n",
        "\n",
        "# --- 1. Define Global Save Paths ---\n",
        "SAVE_DIR = \"/content/drive/MyDrive/aura_education_v7_final\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "THALAMUS_PATH = os.path.join(SAVE_DIR, \"thalamic_router_multitask.pt\")\n",
        "LABEL_MAPS_PATH = os.path.join(SAVE_DIR, \"aura_7_label_maps.json\")\n",
        "\n",
        "# --- 2. The Main Async Test Loop ---\n",
        "async def main_test_loop():\n",
        "\n",
        "    # --- 3. INITIALIZE AND EDUCATE ---\n",
        "    print(\"--- ðŸ§  Initializing Aura 7.0 (Loading LLMs with Unsloth...) ---\")\n",
        "    aura = IntegratedBioNeuralNetwork(\n",
        "        n_experts=10,\n",
        "        hebbian_components=64, # Initial size\n",
        "        llm_model_name=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "    )\n",
        "    print(\"--- Aura LLM Components Loaded ---\")\n",
        "\n",
        "    # Run the \"School\"\n",
        "    await aura.educate_brain() # This will train on go_emotions\n",
        "\n",
        "    # Save the label maps\n",
        "    label_maps = aura.router.label_maps\n",
        "    with open(LABEL_MAPS_PATH, 'w') as f:\n",
        "        json.dump(label_maps, f)\n",
        "\n",
        "    # --- 4. TEST 1: (PRE-TRAINED, \"happy\") ---\n",
        "    print(\"\\n\\n--- ðŸ—£ï¸ TEST 1: Educated Brain, 'Happy' Query ---\")\n",
        "    response_1 = await aura.process_query(\"I am so happy and full of joy!\")\n",
        "    print(f\"\\nFINAL AURA RESPONSE (Happy): {response_1}\")\n",
        "    await aura.save_keyframe(\"happy\") # Save this brain state\n",
        "    day_1_stress = aura.last_run_final_stress\n",
        "\n",
        "    # --- 5. TEST 2: (PRE-TRAINED, \"scared\") ---\n",
        "    print(\"\\n\\n--- ðŸ—£ï¸ TEST 2: Educated Brain, 'Scared' Query ---\")\n",
        "    response_2 = await aura.process_query(\"I am feeling very scared\")\n",
        "    print(f\"\\nFINAL AURA RESPONSE (Scared): {response_2}\")\n",
        "    await aura.save_keyframe(\"scared\") # Save this brain state\n",
        "    day_2_stress = aura.last_run_final_stress\n",
        "\n",
        "    # --- 6. \"DREAM\" CYCLE ---\n",
        "    await aura.run_sleep_cycle(keyframe1_name=\"happy\", keyframe2_name=\"scared\")\n",
        "\n",
        "    # --- 7. TEST 3: (POST-DREAM, \"scared\") ---\n",
        "    print(\"\\n\\n--- ðŸ—£ï¸ TEST 3: Post-Dream Brain, 'Scared' Query (Day 3) ---\")\n",
        "    response_3 = await aura.process_query(\"I am feeling very scared\")\n",
        "    print(f\"\\nFINAL AURA RESPONSE (Scared, Day 3): {response_3}\")\n",
        "    day_3_stress = aura.last_run_final_stress\n",
        "\n",
        "    # --- 8. VERIFICATION ---\n",
        "    print(\"\\n\\n--- ðŸ”¬ TEMPORAL LEARNING VERIFICATION ---\")\n",
        "    print(f\"Day 2 Final Stress (on 'scared'): {day_2_stress:.4f}\")\n",
        "    print(f\"Day 3 Final Stress (on 'scared'): {day_3_stress:.4f}\")\n",
        "\n",
        "    if day_3_stress < (day_2_stress * 0.95): # Look for any reduction\n",
        "        print(\"âœ… SUCCESS: The 'dream' cycle helped process the fear! Stress is lower.\")\n",
        "    else:\n",
        "        print(\"âŒ NEUTRAL/FAILURE: The dream cycle did not reduce stress.\")\n",
        "\n",
        "# --- Run the async main loop ---\n",
        "nest_asyncio.apply()\n",
        "\n",
        "asyncio.run(main_test_loop())"
      ],
      "metadata": {
        "id": "cH_nYmzgf4Eo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}