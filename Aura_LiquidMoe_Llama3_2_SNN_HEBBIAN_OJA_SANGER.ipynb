{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "1EaRNSajynPMZN22RAtLh53agkMfY2eIp",
      "authorship_tag": "ABX9TyNIkFT2woZdimCME6GEVrDv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auralmn/aura_liquidmoe_snn_llama-3.2-3B_Notebooks/blob/main/Aura_LiquidMoe_Llama3_2_SNN_HEBBIAN_OJA_SANGER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aAHUUirjJHFC"
      },
      "outputs": [],
      "source": [
        "# AURA LIQUID MOE (AKA TEST 4.0 - AMYGDALA EXPERTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AURA LIQUIDMOE SNN + LLAMA 3.2 3B UNSLOTH LLM (L4-T4)\n"
      ],
      "metadata": {
        "id": "a1unRLWYJfZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install dependencies"
      ],
      "metadata": {
        "id": "BX6it6TaJqmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip uninstall wandb\n",
        "!pip install transformers torch sentence-transformers accelerate numpy\n",
        "!pip install huggingface_hub\n",
        "# 1. Install Unsloth\n",
        "!pip install \"unsloth[colab-new]\"\n",
        "\n",
        "!pip install huggingface_hub datasets\n",
        "\n",
        "\n",
        "# 3. Authenticate (from Step 13)\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"Hugging Face login successful!\")\n",
        "except ImportError:\n",
        "    print(\"Not in Colab or 'HF_TOKEN' secret not found.\")\n",
        "# --- Log into Hugging Face ---\n",
        "# This is the best way to do it in Colab.\n",
        "# 1. Go to your Colab notebook.\n",
        "# 2. Click the \"Key\" icon (Secrets) in the left-hand sidebar.\n",
        "# 3. Create a new secret named \"HF_TOKEN\".\n",
        "# 4. Paste your Hugging Face Pro token (it starts with \"hf_\") as the value.\n",
        "# 5. Make sure \"Notebook access\" is toggled ON.\n",
        "\n",
        "# This code will then automatically find and use your secret.\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"Hugging Face login successful!\")\n",
        "except ImportError:\n",
        "    print(\"Not in Colab or 'HF_TOKEN' secret not found.\")\n",
        "    # You can paste your token manually if prompted\n",
        "    # login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_f9MqN2TKQz6",
        "outputId": "26fdc906-58fb-4e19-eed3-91c7ec71b81c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.10.5)\n",
            "Requirement already satisfied: unsloth[colab-new] in /usr/local/lib/python3.12/dist-packages (2025.11.3)\n",
            "Requirement already satisfied: unsloth_zoo>=2025.11.4 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2025.11.4)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.45.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (25.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (5.9.5)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.9.35)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (5.29.5)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.0.33.post1)\n",
            "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.48.2)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (3.5.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.2.1)\n",
            "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.3.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (1.11.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.17.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.35.2)\n",
            "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.57.1)\n",
            "Requirement already satisfied: trl!=0.19.0,<=0.23.0,>=0.18.2 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.13.1.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth[colab-new]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth[colab-new]) (0.22.1)\n",
            "Requirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.4->unsloth[colab-new]) (0.14.1)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.4->unsloth[colab-new]) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.4->unsloth[colab-new]) (11.3.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.4->unsloth[colab-new]) (0.19.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth[colab-new]) (8.7.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (4.4.4)\n",
            "\u001b[33mWARNING: unsloth 2025.11.3 does not provide the extra 'triton'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth[colab-new]) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth[colab-new]) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth[colab-new]) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.3.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Hugging Face login successful!\n",
            "Hugging Face login successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SETUP CLEAN AURA INSTANCE"
      ],
      "metadata": {
        "id": "2kGteWhnKuZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enum"
      ],
      "metadata": {
        "id": "EHsp-1lMT8oZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- All Imports ---\n",
        "from enum import Enum\n",
        "import random\n",
        "import uuid\n",
        "import enum\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import itertools\n",
        "import torch\n",
        "from transformers import AutoTokenizer, logging\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "from unsloth import FastLanguageModel\n",
        "from typing import List, Dict, Optional, Union, Any, Tuple\n",
        "from dataclasses import dataclass, field\n",
        "from abc import ABC, abstractmethod\n",
        "from numpy import ndarray\n",
        "import asyncio\n",
        "import io\n",
        "import csv\n",
        "import threading # For Memory Pool\n",
        "import time\n",
        "from datasets import load_dataset # <-- NEW: For GoEmotions\n",
        "\n",
        "# --- PyTorch Imports (for Pre-Training) ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Suppress transformer warnings\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# --- 0. Colab/HF Login ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN, add_to_git_credential=False)\n",
        "    print(\"Hugging Face login successful!\")\n",
        "except (ImportError, KeyError):\n",
        "    print(\"HF_TOKEN secret not found or not in Colab. Ensure you are logged in.\")\n",
        "\n",
        "# --- 1. Memory Pool (from memory_pool.py) ---\n",
        "@dataclass\n",
        "class PoolStats:\n",
        "    hits: int = 0; misses: int = 0; total_allocations: int = 0; peak_usage_mb: float = 0.0\n",
        "class ArrayPool:\n",
        "    \"\"\"High-performance array pool\"\"\"\n",
        "    def __init__(self, max_pool_size_mb: int = 512):\n",
        "        self.max_pool_size = max_pool_size_mb * 1024 * 1024\n",
        "        self.pools: Dict[Tuple[tuple, np.dtype], List[np.ndarray]] = {}\n",
        "        self.current_usage = 0; self.stats = PoolStats(); self._lock = threading.Lock()\n",
        "    def get_array(self, shape: tuple, dtype: np.dtype = np.float32, zero_fill: bool = True) -> np.ndarray:\n",
        "        key = (shape, dtype)\n",
        "        with self._lock:\n",
        "            if key in self.pools and self.pools[key]:\n",
        "                arr = self.pools[key].pop(); self.stats.hits += 1\n",
        "                if zero_fill: arr.fill(0)\n",
        "                return arr\n",
        "            else:\n",
        "                arr = np.empty(shape, dtype=dtype);\n",
        "                if zero_fill: arr.fill(0)\n",
        "                self.stats.misses += 1; self.stats.total_allocations += 1\n",
        "                return arr\n",
        "    def return_array(self, arr: np.ndarray) -> None:\n",
        "        if arr is None: return\n",
        "        key = (arr.shape, arr.dtype); array_size = arr.nbytes\n",
        "        with self._lock:\n",
        "            if self.current_usage + array_size <= self.max_pool_size:\n",
        "                if key not in self.pools: self.pools[key] = []\n",
        "                arr.fill(0); self.pools[key].append(arr); self.current_usage += array_size\n",
        "                self.stats.peak_usage_mb = max(self.stats.peak_usage_mb, self.current_usage / (1024 * 1024))\n",
        "_global_pool = ArrayPool()\n",
        "def get_pooled_array(shape: tuple, dtype: np.dtype = np.float32, zero_fill: bool = True) -> np.ndarray:\n",
        "    return _global_pool.get_array(shape, dtype, zero_fill)\n",
        "def return_pooled_array(arr: np.ndarray) -> None:\n",
        "    _global_pool.return_array(arr)\n",
        "\n",
        "# --- 2. Optimized Whitener (from training_coordinator_optimized.py) ---\n",
        "class OptimizedWhitener:\n",
        "    \"\"\"Memory-efficient online whitener\"\"\"\n",
        "    def __init__(self, dim: int, eps: float = 1e-6, momentum: float = 0.01):\n",
        "        self.dim = dim; self.eps = np.float32(eps); self.momentum = np.float32(momentum)\n",
        "        self.mu = np.zeros(dim, dtype=np.float32); self.var = np.ones(dim, dtype=np.float32)\n",
        "    def transform(self, x: np.ndarray) -> np.ndarray:\n",
        "        if x.dtype != np.float32: x = x.astype(np.float32)\n",
        "        _temp_diff = get_pooled_array((self.dim,), dtype=np.float32)\n",
        "        _temp_result = get_pooled_array((self.dim,), dtype=np.float32)\n",
        "        self.mu *= (1.0 - self.momentum); self.mu += self.momentum * x\n",
        "        np.subtract(x, self.mu, out=_temp_diff)\n",
        "        np.multiply(_temp_diff, _temp_diff, out=_temp_result)\n",
        "        self.var *= (1.0 - self.momentum); self.var += self.momentum * _temp_result\n",
        "        np.sqrt(self.var + self.eps, out=_temp_result)\n",
        "        np.divide(_temp_diff, _temp_result, out=_temp_result)\n",
        "        result_copy = _temp_result.copy()\n",
        "        return_pooled_array(_temp_diff); return_pooled_array(_temp_result)\n",
        "        return result_copy\n",
        "    def state_dict(self) -> Dict: return {\"mu\": self.mu, \"var\": self.var}\n",
        "    def load_state_dict(self, state: Dict): self.mu = state[\"mu\"]; self.var = state[\"var\"]\n",
        "\n",
        "# --- 3. GoEmotions Labels (The Curriculum) ---\n",
        "GOEMOTIONS_LABELS = [\n",
        "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
        "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
        "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
        "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
        "    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
        "]\n",
        "\n",
        "# --- 4. \"Ears\": FeatureGenerator (GoEmotions-Aware) ---\n",
        "class FeatureGenerator:\n",
        "    \"\"\"Builds the 419-dim feature vector\"\"\"\n",
        "    def __init__(self, sbert_model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "        self.SBERT_DIM = 384\n",
        "        self.SINE_LENGTH = 32\n",
        "        self.EXTRA_FEATURES = 3\n",
        "        self.TOTAL_FEATURES = self.SBERT_DIM + self.SINE_LENGTH + self.EXTRA_FEATURES # 419\n",
        "        print(f\"CREATED: FeatureGenerator (Aura 6.0), Features: {self.TOTAL_FEATURES}\")\n",
        "        self.sbert_model = SentenceTransformer(sbert_model_name, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # Educate the feature generator on the *real* emotion labels\n",
        "        self.label_params = self._generate_default_params(GOEMOTIONS_LABELS)\n",
        "        self.tokenizer = self.sbert_model.tokenizer\n",
        "        self.vocab_size = self.tokenizer.vocab_size\n",
        "        self.whitener = OptimizedWhitener(dim=self.TOTAL_FEATURES)\n",
        "\n",
        "    def _generate_default_params(self, labels: List[str]) -> Dict[str, Dict]:\n",
        "        base_freq = 1.5; base_phase = 0.5; params = {}\n",
        "        for idx, label in enumerate(labels):\n",
        "            params[label] = {\"freq\": base_freq + 0.1 * idx, \"amp\": 0.7, \"phase\": base_phase + 0.2 * idx}\n",
        "        return params\n",
        "\n",
        "    def build_features(self, record: Dict[str, Any], sbert_vec: np.ndarray) -> np.ndarray:\n",
        "        prim = record.get(\"plutchik\", {}).get(\"primary\", \"neutral\")\n",
        "        if isinstance(prim, list): prim = prim[0] if prim else \"neutral\"\n",
        "        inten = float(record.get(\"plutchik\", {}).get(\"intensity\", 1.0))\n",
        "        cfg = self.label_params.get(prim, {\"freq\": 1.0, \"amp\": 0.0, \"phase\": 0.0}) # Default to flat line\n",
        "        t = np.linspace(0, 2*np.pi, self.SINE_LENGTH, dtype=np.float32)\n",
        "        emb = (cfg[\"amp\"] * inten * np.sin(cfg[\"freq\"] * t + cfg[\"phase\"])).astype(np.float32)\n",
        "        text = record.get(\"text\", \"\")\n",
        "        extras = np.array([\n",
        "            len(text) / 100.0,\n",
        "            int(\"!\" in text),\n",
        "            int(record.get(\"tone\", \"none\") in {\"euphoric\", \"tense\", \"somber\", \"peaceful\", \"amazed\"})\n",
        "        ], dtype=np.float32)\n",
        "        return np.concatenate([emb, extras, sbert_vec]).astype(np.float32)\n",
        "\n",
        "    def generate_for_query(self, query: str) -> (np.ndarray, List[int]):\n",
        "        record = {\n",
        "            \"text\": query,\n",
        "            \"plutchik\": {\"primary\": \"neutral\", \"intensity\": 0.5},\n",
        "            \"intent\": \"statement\", \"tone\": \"none\"\n",
        "        }\n",
        "        sbert_vec = self.sbert_model.encode(query, normalize_embeddings=True)\n",
        "        x_raw = self.build_features(record, sbert_vec)\n",
        "        x_whitened = self.whitener.transform(x_raw)\n",
        "        token_ids = self.tokenizer.encode(query, add_special_tokens=False)\n",
        "        return x_whitened, token_ids\n",
        "\n",
        "# --- 5. \"Mouth\": ResponseGenerator (Unsloth, Async) ---\n",
        "class ResponseGenerator:\n",
        "    def __init__(self, model_name: str = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"):\n",
        "        print(f\"CREATED: ResponseGenerator (Mouth) using Unsloth on '{model_name}'\")\n",
        "        max_seq_length = 2048; dtype = None; load_in_4bit = True\n",
        "        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_name = model_name, max_seq_length = max_seq_length,\n",
        "            dtype = dtype, load_in_4bit = load_in_4bit,\n",
        "        )\n",
        "        if self.tokenizer.pad_token is None: self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        print(\"   -> Unsloth Llama 3.1 model loaded successfully.\")\n",
        "    def _build_prompt(self, user_query: str, brain_state: dict) -> str:\n",
        "        cns_state = brain_state.get('cns_state', 'ALERT').name\n",
        "        stress = brain_state.get('stress_level', 0.0)\n",
        "        persona = f\"You are Aura, a bio-neural AI. Your current internal state is {cns_state}.\"\n",
        "        if cns_state == 'HYPERVIGILANT' or stress > 1.0:\n",
        "            persona += f\" You are feeling a high-stress level ({stress:.2f}). Your response should be direct and acknowledge the tension.\"\n",
        "        else: persona += \" You are calm and helpful.\"\n",
        "        messages = [{\"role\": \"system\", \"content\": persona}, {\"role\": \"user\", \"content\": user_query}]\n",
        "        return self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    async def generate_response(self, user_query: str, brain_state: dict) -> str:\n",
        "        print(f\"\\n--- ðŸ‘„ ResponseGenerator (Unsloth) ---\"); print(f\"Generating response. Brain state: {brain_state}\")\n",
        "        prompt = self._build_prompt(user_query, brain_state)\n",
        "        inputs = self.tokenizer([prompt], return_tensors=\"pt\", padding=True, truncation=True, max_length=1024).to(\"cuda\")\n",
        "        terminators = [self.tokenizer.eos_token_id, self.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
        "        outputs = await asyncio.to_thread(\n",
        "            self.model.generate, **inputs, max_new_tokens=150, eos_token_id=terminators,\n",
        "            do_sample=True, temperature=0.7, top_p=0.9,\n",
        "        )\n",
        "        response_text = self.tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[-1]:], skip_special_tokens=True)[0]\n",
        "        print(f\"Llama 3.1 (Unsloth) Output: {response_text}\"); return response_text\n",
        "\n",
        "# --- 6. SpikingAttention (k-WTA) (from snn_nlms_moe.py) ---\n",
        "@dataclass\n",
        "class SpikingAttention:\n",
        "    \"\"\"\"\"\"\n",
        "    decay: float = 0.7; theta: float = 1.0; k_winners: int = 5\n",
        "    gain_up: float = 1.5; gain_down: float = 0.6\n",
        "    def compute_gains(self, token_seq: List[int], vocab_size: int) -> Optional[np.ndarray]:\n",
        "        if not token_seq: return None\n",
        "        v: Dict[int, float] = {}; spikes: Dict[int, int] = {}\n",
        "        for j in token_seq:\n",
        "            vj = self.decay * v.get(j, 0.0) + 1.0\n",
        "            if vj >= self.theta: spikes[j] = spikes.get(j, 0) + 1; vj -= self.theta\n",
        "            v[j] = vj\n",
        "        ranked = sorted(spikes.items(), key=lambda kv: (-kv[1], -v.get(kv[0], 0.0)))\n",
        "        winners = set(j for j,_ in ranked[:max(1, self.k_winners)])\n",
        "        gains = np.ones(vocab_size, dtype=np.float64)\n",
        "        seen = set(spikes.keys()) | set(v.keys())\n",
        "        for j in seen:\n",
        "            if 0 <= j < vocab_size: gains[j] = self.gain_up if j in winners else self.gain_down\n",
        "        return gains\n",
        "\n",
        "# --- 7. \"Expert Neuron\": NLMSHead (from snn_nlms_moe.py) ---\n",
        "class NLMSHead:\n",
        "    \"\"\"This is the 'Expert'. It holds the weights and performs learning.\"\"\"\n",
        "    def __init__(self, n_features: int, n_outputs: int, vocab_size: int,\n",
        "                 attention_config: Dict, mu: float = 0.1):\n",
        "        self.n_features = n_features; self.n_outputs = n_outputs; self.vocab_size = vocab_size\n",
        "        self.attention_config = attention_config; self.mu = mu; self._lock = asyncio.Lock()\n",
        "        self.w = np.zeros((self.n_features, self.n_outputs), dtype=np.float64)\n",
        "        self.b = np.zeros(self.n_outputs, dtype=np.float64)\n",
        "        self.spiking_attention = SpikingAttention(**self.attention_config)\n",
        "        self.last_error = np.zeros(self.n_outputs, dtype=np.float64)\n",
        "        self.last_output = np.zeros(self.n_outputs, dtype=np.float64)\n",
        "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
        "         x = np.asarray(x, dtype=np.float64).reshape(-1); return (x @ self.w) + self.b\n",
        "    async def load_weights(self, w_path: str, b_path: str):\n",
        "        \"\"\"NEW: Load pre-trained weights from .npy files\"\"\"\n",
        "        async with self._lock:\n",
        "            try:\n",
        "                self.w = np.load(w_path); self.b = np.load(b_path)\n",
        "                print(f\"   -> Successfully loaded weights: {w_path} (W:{self.w.shape}, b:{self.b.shape})\")\n",
        "            except Exception as e:\n",
        "                print(f\"   -> WARNING: Failed to load weights from {w_path}. Starting from zero. Error: {e}\")\n",
        "    async def step(self, x: np.ndarray, y_true: np.ndarray | float, token_ids: List[int]) -> np.ndarray:\n",
        "        async with self._lock:\n",
        "            x = np.asarray(x, dtype=np.float64).reshape(-1)\n",
        "            y_hat = self.predict(x); self.last_output = y_hat\n",
        "            y_true_vec = (np.array([y_true]) if np.isscalar(y_true)\n",
        "                          else np.asarray(y_true, dtype=np.float64).reshape(-1))\n",
        "            e = y_true_vec - y_hat; self.last_error = e\n",
        "            attention_gains = self.spiking_attention.compute_gains(token_ids, self.vocab_size)\n",
        "            avg_gain = 1.0\n",
        "            if attention_gains is not None and token_ids:\n",
        "                gains_for_seq = [attention_gains[token] for token in token_ids if 0 <= token < self.vocab_size]\n",
        "                if gains_for_seq: avg_gain = np.mean(gains_for_seq)\n",
        "            modulated_mu = self.mu * avg_gain\n",
        "            x_norm_sq = 1e-8 + float(x @ x)\n",
        "            grad = (x / x_norm_sq)[:, None] * e[None, :]\n",
        "            self.w += modulated_mu * grad; self.b += modulated_mu * e\n",
        "            return y_hat\n",
        "    def state_dict(self) -> Dict: return {\"w\": self.w, \"b\": self.b}\n",
        "    def load_state_dict(self, state: Dict): self.w = state[\"w\"]; self.b = state[\"b\"]\n",
        "\n",
        "# --- 8. CNS & ThalamicRouter (Educated) ---\n",
        "class ConsciousnessLevel(Enum):\n",
        "    DEEP_SLEEP = 0; ASLEEP = 1; ALERT = 2; FOCUSED = 3; HYPERVIGILANT = 4\n",
        "class CentralNervousSystem:\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self):\n",
        "        self.consciousness_level = ConsciousnessLevel.ALERT\n",
        "        self.stress_level = 0.0 # This is our 'cortisol'\n",
        "        print(\"CREATED: CentralNervousSystem (CNS)\")\n",
        "    def set_consciousness(self, level: ConsciousnessLevel):\n",
        "        if self.consciousness_level != level:\n",
        "            self.consciousness_level = level; print(f\"CNS: Consciousness set to {level.name}\")\n",
        "    def update_stress(self, error: float):\n",
        "        new_stress = abs(error) * 1.5\n",
        "        self.stress_level = (self.stress_level * 0.5) + (new_stress * 0.5)\n",
        "        self.stress_level = max(0.0, self.stress_level - 0.1)\n",
        "        if self.stress_level > 1.0:\n",
        "            self.set_consciousness(ConsciousnessLevel.HYPERVIGILANT)\n",
        "        else:\n",
        "            self.set_consciousness(ConsciousnessLevel.ALERT)\n",
        "\n",
        "class ThalamicRouter:\n",
        "    \"\"\"\n",
        "    This router is now \"educated\" with the GoEmotions label map.\n",
        "    It provides target signals (y_true) for the experts.\n",
        "    \"\"\"\n",
        "    def __init__(self, label_maps: Dict):\n",
        "        # --- THIS IS THE FIX ---\n",
        "        self.label_maps = label_maps  # <-- ADD THIS LINE\n",
        "        # --- END FIX ---\n",
        "\n",
        "        self.emotion_map = label_maps.get('emotion', {})\n",
        "        self.intent_map = label_maps.get('intent', {})\n",
        "        print(f\"CREATED: ThalamicRouter (Educated with {len(self.emotion_map)} emotions)\")\n",
        "\n",
        "    def get_target_signals(self, query: str) -> dict:\n",
        "        query = query.lower()\n",
        "        signals = {\n",
        "            'emotion': self.emotion_map.get('neutral', 0.0),\n",
        "            'intent': self.intent_map.get('statement', 0.0)\n",
        "        }\n",
        "        # Keyword-based mapping to the *real* GoEmotions labels\n",
        "        if 'scared' in query or 'fear' in query or 'anxious' in query or 'nervous' in query:\n",
        "            signals['emotion'] = self.emotion_map.get('fear', self.emotion_map.get('nervousness', 0.0))\n",
        "        elif 'happy' in query or 'joy' in query or 'excited' in query:\n",
        "            signals['emotion'] = self.emotion_map.get('joy', self.emotion_map.get('excitement', 0.0))\n",
        "        elif 'angry' in query or 'annoyed' in query:\n",
        "            signals['emotion'] = self.emotion_map.get('anger', self.emotion_map.get('annoyance', 0.0))\n",
        "        elif 'sad' in query or 'grief' in query:\n",
        "            signals['emotion'] = self.emotion_map.get('sadness', self.emotion_map.get('grief', 0.0))\n",
        "\n",
        "        if '?' in query:\n",
        "            signals['intent'] = self.intent_map.get('question', 0.0)\n",
        "        elif '!' in query:\n",
        "            signals['intent'] = self.intent_map.get('exclamation', 0.0)\n",
        "\n",
        "        return signals\n",
        "\n",
        "# --- 9. The Final IBNN (Aura 6.0 - Pre-Trained) ---\n",
        "class IntegratedBioNeuralNetwork:\n",
        "    \"\"\"\n",
        "    This is Aura 6.0. It learns from a \"School\" (offline training)\n",
        "    and then fine-tunes in real-time (online learning).\n",
        "    \"\"\"\n",
        "    def __init__(self, llm_model_name: str = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"):\n",
        "        print(\"--- ðŸ§  Initializing Aura 6.0 (Pre-Trained) ---\")\n",
        "        self.feature_gen = FeatureGenerator()\n",
        "        self.response_gen = ResponseGenerator(llm_model_name)\n",
        "        self.cns = CentralNervousSystem()\n",
        "        self.feature_dim = self.feature_gen.TOTAL_FEATURES\n",
        "        self.vocab_size = self.feature_gen.vocab_size\n",
        "        self.experts: Dict[str, NLMSHead] = {}\n",
        "        self.router = None # Will be set after education\n",
        "        self.education_dir = \"/content/drive/MyDrive/aura_education_weights\" # Save to Drive\n",
        "        os.makedirs(self.education_dir, exist_ok=True)\n",
        "        print(\"--- Aura 6.0 Brain Initialized (Awaiting Education) ---\")\n",
        "\n",
        "    def _add_expert(self, name: str, n_outputs: int, attention_config: dict):\n",
        "        head = NLMSHead(\n",
        "            n_features=self.feature_dim,\n",
        "            n_outputs=n_outputs,\n",
        "            vocab_size=self.vocab_size,\n",
        "            attention_config=attention_config,\n",
        "            mu=0.05\n",
        "        )\n",
        "        self.experts[name] = head\n",
        "        print(f\"Added Expert: {name} (Output dim: {n_outputs})\")\n",
        "\n",
        "    async def educate_brain(self):\n",
        "        \"\"\"\n",
        "        Runs the 'School' pipeline to pre-train experts from GoEmotions.\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"\\n--- ðŸŽ“ STARTING OFFLINE EDUCATION (GoEmotions) ---\")\n",
        "\n",
        "        # 1. Load GoEmotions dataset\n",
        "        print(\"Loading 'goemotions' dataset from Hugging Face...\")\n",
        "        dataset = load_dataset(\"google-research-datasets/go_emotions\", \"raw\")['train']\n",
        "        # Let's use a subset for speed in Colab\n",
        "        dataset = dataset.shuffle(seed=42).select(range(5000)) # 5000 samples\n",
        "\n",
        "        all_texts = dataset['text']\n",
        "\n",
        "        # 2. Precompute SBERT in a thread\n",
        "        print(f\"Pre-computing SBERT embeddings for {len(all_texts)} texts...\")\n",
        "        sbert_embeddings = await asyncio.to_thread(\n",
        "            self.feature_gen.sbert_model.encode,\n",
        "            all_texts, normalize_embeddings=True, batch_size=64\n",
        "        )\n",
        "\n",
        "        # 3. Create Label Maps\n",
        "        emotion_labels = GOEMOTIONS_LABELS\n",
        "        # Mock 'intent' labels as GoEmotions doesn't have them\n",
        "        intent_labels = [\"question\", \"statement\", \"exclamation\", \"request\", \"none\"]\n",
        "        label_maps = {\n",
        "            'emotion': {label: idx for idx, label in enumerate(emotion_labels)},\n",
        "            'intent': {label: idx for idx, label in enumerate(intent_labels)},\n",
        "        }\n",
        "\n",
        "        # 4. Build Features and Tensorize\n",
        "        print(\"Building features and tensorizing...\")\n",
        "        X_features, y_emotion, y_intent = [], [], []\n",
        "\n",
        "        for i, record in enumerate(dataset):\n",
        "            # Create a mock 'plutchik' record from the multi-label data\n",
        "            primary_emotion = 'neutral'\n",
        "            for label in emotion_labels:\n",
        "                if label != 'neutral' and record[label] == 1:\n",
        "                    primary_emotion = label\n",
        "                    break # Just take the first one\n",
        "\n",
        "            mock_record = {\n",
        "                \"text\": record['text'],\n",
        "                \"plutchik\": {\"primary\": primary_emotion, \"intensity\": 1.0},\n",
        "                \"intent\": \"question\" if \"?\" in record['text'] else \"statement\"\n",
        "            }\n",
        "\n",
        "            X_features.append(self.feature_gen.build_features(mock_record, sbert_embeddings[i]))\n",
        "            y_emotion.append(label_maps['emotion'].get(primary_emotion, 27)) # 27 is 'neutral'\n",
        "            y_intent.append(label_maps['intent'].get(mock_record['intent'], 1)) # 1 is 'statement'\n",
        "\n",
        "        X_train = torch.tensor(np.stack(X_features), dtype=torch.float32)\n",
        "        y_emotion_train = torch.tensor(y_emotion, dtype=torch.long)\n",
        "        y_intent_train = torch.tensor(y_intent, dtype=torch.long)\n",
        "\n",
        "        # --- 5. Train \"Emotion\" Expert ---\n",
        "        print(f\"Training Emotion expert ({self.feature_gen.TOTAL_FEATURES} -> {len(emotion_labels)} classes)...\")\n",
        "        emotion_model = LinearTorchModel(self.feature_gen.TOTAL_FEATURES, len(emotion_labels))\n",
        "        optimizer = optim.AdamW(emotion_model.parameters(), lr=5e-3)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        for epoch in range(15): # 15 epochs\n",
        "            optimizer.zero_grad(); loss = criterion(emotion_model(X_train), y_emotion_train)\n",
        "            loss.backward(); optimizer.step()\n",
        "        preds = emotion_model(X_train).argmax(dim=1); acc = (preds == y_emotion_train).float().mean().item()\n",
        "        print(f\"  -> Emotion training complete. Final Acc: {acc:.2f}\")\n",
        "\n",
        "        # --- 6. Train \"Intent\" Expert ---\n",
        "        print(f\"Training Intent expert ({self.feature_gen.TOTAL_FEATURES} -> {len(intent_labels)} classes)...\")\n",
        "        intent_model = LinearTorchModel(self.feature_gen.TOTAL_FEATURES, len(intent_labels))\n",
        "        optimizer = optim.AdamW(intent_model.parameters(), lr=5e-3)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        for epoch in range(10): # 10 epochs\n",
        "            optimizer.zero_grad(); loss = criterion(intent_model(X_train), y_intent_train)\n",
        "            loss.backward(); optimizer.step()\n",
        "        preds = intent_model(X_train).argmax(dim=1); acc = (preds == y_intent_train).float().mean().item()\n",
        "        print(f\"  -> Intent training complete. Final Acc: {acc:.2f}\")\n",
        "\n",
        "        # --- 7. Export Weights to Google Drive ---\n",
        "        print(f\"Exporting educated weights to {self.education_dir}...\")\n",
        "        export_linear_weights(emotion_model, self.education_dir, \"emotion_classifier\")\n",
        "        export_linear_weights(intent_model, self.education_dir, \"intent_classifier\")\n",
        "\n",
        "        # --- 8. \"Mind Upload\" - Load weights into NLMSHead Experts ---\n",
        "        await self.load_education(label_maps, weights_dir=self.education_dir)\n",
        "\n",
        "        print(\"--- ðŸŽ“ OFFLINE EDUCATION COMPLETE ---\")\n",
        "\n",
        "    async def load_education(self, label_maps: Dict, weights_dir: str = \".\"):\n",
        "        \"\"\"\n",
        "        Create experts based on label maps and load pre-trained weights.\n",
        "\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- ðŸ“š Loading Education from {weights_dir} ---\")\n",
        "        self.experts.clear() # Clear any old experts\n",
        "\n",
        "        if 'emotion' in label_maps:\n",
        "            self._add_expert(\n",
        "                name='emotion',\n",
        "                n_outputs=len(label_maps['emotion']),\n",
        "                attention_config={'decay': 0.6, 'k_winners': 4, 'gain_up': 2.0, 'gain_down': 0.4}\n",
        "            )\n",
        "            await self.experts['emotion'].load_weights(\n",
        "                w_path=os.path.join(weights_dir, \"emotion_classifier_W.npy\"),\n",
        "                b_path=os.path.join(weights_dir, \"emotion_classifier_b.npy\")\n",
        "            )\n",
        "        if 'intent' in label_maps:\n",
        "            self._add_expert(\n",
        "                name='intent',\n",
        "                n_outputs=len(label_maps['intent']),\n",
        "                attention_config={'decay': 0.7, 'k_winners': 5, 'gain_up': 1.5, 'gain_down': 0.7}\n",
        "            )\n",
        "            await self.experts['intent'].load_weights(\n",
        "                w_path=os.path.join(weights_dir, \"intent_classifier_W.npy\"),\n",
        "                b_path=os.path.join(weights_dir, \"intent_classifier_b.npy\")\n",
        "            )\n",
        "        self.router = ThalamicRouter(label_maps)\n",
        "\n",
        "    async def process_query(self, query: str) -> str:\n",
        "        print(f\"\\n--- â˜€ï¸ PROCESSING QUERY (Aura 6.0): '{query}' ---\")\n",
        "        if not self.router:\n",
        "            return \"I am uneducated. Please run `await aura.educate_brain()`.\"\n",
        "\n",
        "        target_signals = self.router.get_target_signals(query)\n",
        "        cns_level = self.cns.consciousness_level\n",
        "        x_whitened, token_ids = self.feature_gen.generate_for_query(query)\n",
        "\n",
        "        tasks = []\n",
        "        for name, expert in self.experts.items():\n",
        "            num_classes = expert.n_outputs\n",
        "            target_index = target_signals.get(name, 0)\n",
        "            y_true = np.zeros(num_classes)\n",
        "            y_true[target_index] = 1.0 # One-hot target\n",
        "            tasks.append(expert.step(x_whitened, y_true, token_ids))\n",
        "        await asyncio.gather(*tasks)\n",
        "\n",
        "        emotion_error_vec = self.experts['emotion'].last_error\n",
        "        stress = np.mean(np.abs(emotion_error_vec))\n",
        "        self.cns.update_stress(stress)\n",
        "\n",
        "        emotion_pred_index = self.experts['emotion'].last_output.argmax()\n",
        "        emotion_pred_label = GOEMOTIONS_LABELS[emotion_pred_index]\n",
        "        print(f\"Emotion Prediction: {emotion_pred_label} (Error/Stress: {stress:.3f})\")\n",
        "\n",
        "        final_brain_state = {\n",
        "            'cns_state': self.cns.consciousness_level,\n",
        "            'stress_level': self.cns.stress_level,\n",
        "        }\n",
        "        response = await self.response_gen.generate_response(query, final_brain_state)\n",
        "        self.last_run_final_stress = self.cns.stress_level\n",
        "        return response\n",
        "\n",
        "    async def save_brain(self, path: str):\n",
        "        \"\"\"Saves the *learned* (fine-tuned) brain state.\"\"\"\n",
        "        print(f\"\\n--- ðŸ’¾ Saving brain state to {path} ---\")\n",
        "        state_dict = {}\n",
        "        for name, expert in self.experts.items():\n",
        "            async with expert._lock:\n",
        "                state_dict[f\"expert_{name}_w\"] = expert.w\n",
        "                state_dict[f\"expert_{name}_b\"] = expert.b\n",
        "        state_dict[\"whitener_mu\"] = self.feature_gen.whitener.mu\n",
        "        state_dict[\"whitener_var\"] = self.feature_gen.whitener.var\n",
        "        await asyncio.to_thread(np.savez_compressed, path, **state_dict)\n",
        "        print(\"--- ðŸ’¾ Save complete ---\")\n",
        "\n",
        "    async def load_brain(self, path: str):\n",
        "        \"\"\"Loads a saved brain state from a .npz file.\"\"\"\n",
        "        print(f\"\\n--- ðŸ§  Loading brain state from {path} ---\")\n",
        "        try:\n",
        "            data = np.load(path)\n",
        "            for name, expert in self.experts.items():\n",
        "                async with expert._lock:\n",
        "                    if f\"expert_{name}_w\" in data:\n",
        "                        expert.w = data[f\"expert_{name}_w\"]\n",
        "                        expert.b = data[f\"expert_{name}_b\"]\n",
        "                        print(f\"   -> Loaded weights for expert: {name}\")\n",
        "            if \"whitener_mu\" in data:\n",
        "                self.feature_gen.whitener.mu = data[\"whitener_mu\"]\n",
        "                self.feature_gen.whitener.var = data[\"whitener_var\"]\n",
        "            print(\"--- ðŸ§  Load complete ---\")\n",
        "        except Exception as e:\n",
        "            print(f\"--- âŒ ERROR: Failed to load brain state. {e} ---\")\n",
        "\n",
        "# --- 11. PyTorch Models (for the \"School\") ---\n",
        "class LinearTorchModel(nn.Module):\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, input_dim: int, num_classes: int):\n",
        "        super().__init__(); self.fc = nn.Linear(input_dim, num_classes)\n",
        "    def forward(self, x): return self.fc(x)\n",
        "\n",
        "def export_linear_weights(model: LinearTorchModel, output_dir: str, task_name: str):\n",
        "    \"\"\"\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    W = model.fc.weight.detach().cpu().numpy().T\n",
        "    b = model.fc.bias.detach().cpu().numpy()\n",
        "    np.save(os.path.join(output_dir, f\"{task_name}_W.npy\"), W)\n",
        "    np.save(os.path.join(output_dir, f\"{task_name}_b.npy\"), b)\n",
        "    print(f\"Exported {task_name} weights: W{W.shape}, b{b.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0WT5RvETJUF",
        "outputId": "639d278d-b9f9-49ef-975b-ee6d899b9220"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face login successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- This is the test cell for Aura 6.0 ---\n",
        "# It must be run in a cell *after* Cell 50\n",
        "import os\n",
        "# --- 1. Mount Google Drive ---\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    SAVE_DIR = \"/content/drive/MyDrive/aura_education_weights\"\n",
        "    print(f\"Google Drive mounted. Will save/load brain from: {SAVE_DIR}\")\n",
        "except ImportError:\n",
        "    print(\"Not in Colab. Saving to local directory './aura_brain_state_v6'\")\n",
        "    SAVE_DIR = \"./aura_brain_state_v6\"\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "BRAIN_STATE_FILE = os.path.join(SAVE_DIR, \"aura_6_memory.npz\")\n",
        "LABEL_MAPS_FILE = os.path.join(SAVE_DIR, \"aura_6_labels.json\")\n",
        "\n",
        "\n",
        "# --- 2. The Main Async Test Loop ---\n",
        "async def main_test_loop():\n",
        "\n",
        "    # --- 3. INITIALIZE AND EDUCATE (Day 1) ---\n",
        "    print(\"--- ðŸ§  Initializing Aura 6.0 (Loading LLMs with Unsloth...) ---\")\n",
        "    aura_day_1 = IntegratedBioNeuralNetwork(\n",
        "        llm_model_name=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "    )\n",
        "    print(\"--- Aura LLM Components Loaded ---\")\n",
        "\n",
        "    # Run the \"School\"\n",
        "    await aura_day_1.educate_brain()\n",
        "\n",
        "    # Save the label maps\n",
        "    label_maps = aura_day_1.router.label_maps\n",
        "    with open(LABEL_MAPS_FILE, 'w') as f:\n",
        "        json.dump(label_maps, f)\n",
        "\n",
        "    # --- 4. TEST 1: (PRE-TRAINED, \"scared\") ---\n",
        "    print(\"\\n\\n--- ðŸ—£ï¸ TEST 1: Educated Brain, 'Scared' Query ---\")\n",
        "    response_1 = await aura_day_1.process_query(\"I am feeling very scared\")\n",
        "    print(f\"\\nFINAL AURA RESPONSE (Day 1): {response_1}\")\n",
        "    day_1_stress = aura_day_1.last_run_final_stress\n",
        "\n",
        "    # --- 5. TEST 2: (PRE-TRAINED, \"happy\") ---\n",
        "    print(\"\\n\\n--- ðŸ—£ï¸ TEST 2: Educated Brain, 'Happy' Query ---\")\n",
        "    response_2 = await aura_day_1.process_query(\"I am so happy and full of joy!\")\n",
        "    print(f\"\\nFINAL AURA RESPONSE (Day 1, Happy): {response_2}\")\n",
        "\n",
        "    # --- 6. SAVE THE BRAIN ---\n",
        "    # At this point, the brain has been fine-tuned on \"scared\" and \"happy\"\n",
        "    await aura_day_1.save_brain(BRAIN_STATE_FILE)\n",
        "\n",
        "    # --- 7. LOAD THE BRAIN (Simulate a restart) ---\n",
        "    print(\"\\n\\n--- ðŸ§  Initializing NEW Aura 6.0 (Blank Brain) ---\")\n",
        "    aura_day_2 = IntegratedBioNeuralNetwork(\n",
        "        llm_model_name=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "    )\n",
        "\n",
        "    # Give it the *same* education so its experts are the right shape\n",
        "    print(\"--- Loading 'School' curriculum (label maps) ---\")\n",
        "    with open(LABEL_MAPS_FILE, 'r') as f:\n",
        "        loaded_label_maps = json.load(f)\n",
        "\n",
        "    # Load the *weights*\n",
        "    await aura_day_2.load_education(label_maps=loaded_label_maps, weights_dir=SAVE_DIR)\n",
        "    # Load the *fine-tuned state*\n",
        "    await aura_day_2.load_brain(BRAIN_STATE_FILE)\n",
        "\n",
        "    # --- 8. TEST 3: (LOADED BRAIN, \"scared\") ---\n",
        "    print(\"\\n\\n--- ðŸ—£ï¸ TEST 3: LOADED Brain, 'Scared' Query (Day 2) ---\")\n",
        "    response_3 = await aura_day_2.process_query(\"I am feeling very scared\")\n",
        "    print(f\"\\nFINAL AURA RESPONSE (Day 2): {response_3}\")\n",
        "    day_2_stress = aura_day_2.last_run_final_stress\n",
        "\n",
        "    # --- 9. VERIFICATION ---\n",
        "    print(\"\\n\\n--- ðŸ”¬ PERSISTENCE VERIFICATION ---\")\n",
        "    print(f\"Day 1 Final Stress (on 'scared'): {day_1_stress:.4f}\")\n",
        "    print(f\"Day 2 Final Stress (on 'scared'): {day_2_stress:.4f}\")\n",
        "\n",
        "    if day_2_stress < (day_1_stress * 1.1): # Allow for small floating point differences\n",
        "        print(\"âœ… SUCCESS: The loaded brain's stress response was persistent. Learning was saved and restored!\")\n",
        "    else:\n",
        "        print(\"âŒ FAILURE: The loaded brain's stress was different. Persistence failed.\")\n",
        "\n",
        "# --- Run the async main loop ---\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "asyncio.run(main_test_loop())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IurdrqdCTdc8",
        "outputId": "c0864a81-91c9-45e2-ff64-4fb16dd60657"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted. Will save/load brain from: /content/drive/MyDrive/aura_education_weights\n",
            "--- ðŸ§  Initializing Aura 6.0 (Loading LLMs with Unsloth...) ---\n",
            "--- ðŸ§  Initializing Aura 6.0 (Pre-Trained) ---\n",
            "CREATED: FeatureGenerator (Aura 6.0), Features: 419\n",
            "CREATED: ResponseGenerator (Mouth) using Unsloth on 'meta-llama/Llama-3.2-3B-Instruct'\n",
            "==((====))==  Unsloth 2025.11.3: Fast Llama patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "   -> Unsloth Llama 3.1 model loaded successfully.\n",
            "CREATED: CentralNervousSystem (CNS)\n",
            "--- Aura 6.0 Brain Initialized (Awaiting Education) ---\n",
            "--- Aura LLM Components Loaded ---\n",
            "\n",
            "--- ðŸŽ“ STARTING OFFLINE EDUCATION (GoEmotions) ---\n",
            "Loading 'goemotions' dataset from Hugging Face...\n",
            "Pre-computing SBERT embeddings for 5000 texts...\n",
            "Building features and tensorizing...\n",
            "Training Emotion expert (419 -> 28 classes)...\n",
            "  -> Emotion training complete. Final Acc: 0.77\n",
            "Training Intent expert (419 -> 5 classes)...\n",
            "  -> Intent training complete. Final Acc: 0.86\n",
            "Exporting educated weights to /content/drive/MyDrive/aura_education_weights...\n",
            "Exported emotion_classifier weights: W(419, 28), b(28,)\n",
            "Exported intent_classifier weights: W(419, 5), b(5,)\n",
            "\n",
            "--- ðŸ“š Loading Education from /content/drive/MyDrive/aura_education_weights ---\n",
            "Added Expert: emotion (Output dim: 28)\n",
            "   -> Successfully loaded weights: /content/drive/MyDrive/aura_education_weights/emotion_classifier_W.npy (W:(419, 28), b:(28,))\n",
            "Added Expert: intent (Output dim: 5)\n",
            "   -> Successfully loaded weights: /content/drive/MyDrive/aura_education_weights/intent_classifier_W.npy (W:(419, 5), b:(5,))\n",
            "CREATED: ThalamicRouter (Educated with 28 emotions)\n",
            "--- ðŸŽ“ OFFLINE EDUCATION COMPLETE ---\n",
            "\n",
            "\n",
            "--- ðŸ—£ï¸ TEST 1: Educated Brain, 'Scared' Query ---\n",
            "\n",
            "--- â˜€ï¸ PROCESSING QUERY (Aura 6.0): 'I am feeling very scared' ---\n",
            "Emotion Prediction: neutral (Error/Stress: 0.401)\n",
            "\n",
            "--- ðŸ‘„ ResponseGenerator (Unsloth) ---\n",
            "Generating response. Brain state: {'cns_state': <ConsciousnessLevel.ALERT: 2>, 'stress_level': np.float64(0.20066309829405102)}\n",
            "Llama 3.1 (Unsloth) Output: I'm here to listen and help. It's completely normal to feel scared sometimes. Would you like to talk about what's causing your fear? Sometimes sharing your thoughts and feelings can help you process and feel better. I'm here to listen without judgment.\n",
            "\n",
            "FINAL AURA RESPONSE (Day 1): I'm here to listen and help. It's completely normal to feel scared sometimes. Would you like to talk about what's causing your fear? Sometimes sharing your thoughts and feelings can help you process and feel better. I'm here to listen without judgment.\n",
            "\n",
            "\n",
            "--- ðŸ—£ï¸ TEST 2: Educated Brain, 'Happy' Query ---\n",
            "\n",
            "--- â˜€ï¸ PROCESSING QUERY (Aura 6.0): 'I am so happy and full of joy!' ---\n",
            "Emotion Prediction: neutral (Error/Stress: 0.515)\n",
            "\n",
            "--- ðŸ‘„ ResponseGenerator (Unsloth) ---\n",
            "Generating response. Brain state: {'cns_state': <ConsciousnessLevel.ALERT: 2>, 'stress_level': np.float64(0.3864133184351154)}\n",
            "Llama 3.1 (Unsloth) Output: I can sense your positive emotions! It's great to interact with someone who is feeling joyful and enthusiastic. I'm here to help and provide assistance if you need anything. Would you like to talk about what's bringing you happiness today, or perhaps I can offer some suggestions to help you maintain your positive mood?\n",
            "\n",
            "FINAL AURA RESPONSE (Day 1, Happy): I can sense your positive emotions! It's great to interact with someone who is feeling joyful and enthusiastic. I'm here to help and provide assistance if you need anything. Would you like to talk about what's bringing you happiness today, or perhaps I can offer some suggestions to help you maintain your positive mood?\n",
            "\n",
            "--- ðŸ’¾ Saving brain state to /content/drive/MyDrive/aura_education_weights/aura_6_memory.npz ---\n",
            "--- ðŸ’¾ Save complete ---\n",
            "\n",
            "\n",
            "--- ðŸ§  Initializing NEW Aura 6.0 (Blank Brain) ---\n",
            "--- ðŸ§  Initializing Aura 6.0 (Pre-Trained) ---\n",
            "CREATED: FeatureGenerator (Aura 6.0), Features: 419\n",
            "CREATED: ResponseGenerator (Mouth) using Unsloth on 'meta-llama/Llama-3.2-3B-Instruct'\n",
            "==((====))==  Unsloth 2025.11.3: Fast Llama patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "   -> Unsloth Llama 3.1 model loaded successfully.\n",
            "CREATED: CentralNervousSystem (CNS)\n",
            "--- Aura 6.0 Brain Initialized (Awaiting Education) ---\n",
            "--- Loading 'School' curriculum (label maps) ---\n",
            "\n",
            "--- ðŸ“š Loading Education from /content/drive/MyDrive/aura_education_weights ---\n",
            "Added Expert: emotion (Output dim: 28)\n",
            "   -> Successfully loaded weights: /content/drive/MyDrive/aura_education_weights/emotion_classifier_W.npy (W:(419, 28), b:(28,))\n",
            "Added Expert: intent (Output dim: 5)\n",
            "   -> Successfully loaded weights: /content/drive/MyDrive/aura_education_weights/intent_classifier_W.npy (W:(419, 5), b:(5,))\n",
            "CREATED: ThalamicRouter (Educated with 28 emotions)\n",
            "\n",
            "--- ðŸ§  Loading brain state from /content/drive/MyDrive/aura_education_weights/aura_6_memory.npz ---\n",
            "   -> Loaded weights for expert: emotion\n",
            "   -> Loaded weights for expert: intent\n",
            "--- ðŸ§  Load complete ---\n",
            "\n",
            "\n",
            "--- ðŸ—£ï¸ TEST 3: LOADED Brain, 'Scared' Query (Day 2) ---\n",
            "\n",
            "--- â˜€ï¸ PROCESSING QUERY (Aura 6.0): 'I am feeling very scared' ---\n",
            "Emotion Prediction: neutral (Error/Stress: 0.295)\n",
            "\n",
            "--- ðŸ‘„ ResponseGenerator (Unsloth) ---\n",
            "Generating response. Brain state: {'cns_state': <ConsciousnessLevel.ALERT: 2>, 'stress_level': np.float64(0.1209677232316465)}\n",
            "Llama 3.1 (Unsloth) Output: I'm so sorry to hear that you're feeling scared. I'm here to listen and help if I can. Would you like to talk about what's causing your fear? Sometimes sharing what's on your mind can help you feel better. I'm all ears (or rather, all circuits).\n",
            "\n",
            "FINAL AURA RESPONSE (Day 2): I'm so sorry to hear that you're feeling scared. I'm here to listen and help if I can. Would you like to talk about what's causing your fear? Sometimes sharing what's on your mind can help you feel better. I'm all ears (or rather, all circuits).\n",
            "\n",
            "\n",
            "--- ðŸ”¬ PERSISTENCE VERIFICATION ---\n",
            "Day 1 Final Stress (on 'scared'): 0.2007\n",
            "Day 2 Final Stress (on 'scared'): 0.1210\n",
            "âœ… SUCCESS: The loaded brain's stress response was persistent. Learning was saved and restored!\n"
          ]
        }
      ]
    }
  ]
}